[
  {
    "objectID": "posts/20240517-interesting-etymologies/index.html",
    "href": "posts/20240517-interesting-etymologies/index.html",
    "title": "Interesting Etymologies Running List",
    "section": "",
    "text": "This is a running list of etymologies that I think are neat."
  },
  {
    "objectID": "posts/20240517-interesting-etymologies/index.html#temujin",
    "href": "posts/20240517-interesting-etymologies/index.html#temujin",
    "title": "Interesting Etymologies Running List",
    "section": "Temujin",
    "text": "Temujin\nGenghis Khan was just a title; his real name was Temujin. Temujin is a Mongolic name that was probably borrowed from the Proto-Turkic *temürči meaning “blacksmith”. The -ci suffix denotes a person who works with something, in this case *temür, or iron. Modern Turkish’s “demirci”, also meaning “blacksmith”, is a descendent of this word and a cognate to Temujin. These names and their friends were and are still common throughout the region. For example, Timur (also known as Tamerlame), of the Timurid Empire, shares the same root—Timur, like Turkish demir, means iron."
  },
  {
    "objectID": "posts/20240517-interesting-etymologies/index.html#ordu",
    "href": "posts/20240517-interesting-etymologies/index.html#ordu",
    "title": "Interesting Etymologies Running List",
    "section": "Ordu",
    "text": "Ordu\nOrdu is the Turkish word for “army”. It actually has an English cognate, “horde”! Quite a few European languages seem to have picked this word up via contact with Central Asians. The most likely source appears to be Proto-Turkic, which makes sense given the role they played in Central Asian empires. But there’s another cognate to ordu that’s even more interesting: Urdu, the national language of Pakistan. The Mughal Empire of India established Persian as the official language of the empire, and the Hindustani dialect spoken in the military camps came to be referred to as “Zaban-e-Urdu” in Persian, or “language of the army”, eventually being shortened to just “Urdu”."
  },
  {
    "objectID": "posts/20240517-interesting-etymologies/index.html#rickshaw",
    "href": "posts/20240517-interesting-etymologies/index.html#rickshaw",
    "title": "Interesting Etymologies Running List",
    "section": "Rickshaw",
    "text": "Rickshaw\nRickshaws are small, hand-drawn passenger carts that were (and in some places, are) popular in Asia. It comes from the Japanese word 人力車 jinrikisha. But when it entered the English language, it actually already had a cognate, a word that came from the same root: wheel.\nFive thousand years, a group called the Yamnaya used carts and wagons on the Ukrainian Steppe. This group is generally accepted to be the source of the Indo-European Languages—a language family encompassing languages as diverse as English, Persian, and Hindi. Their word for wheel was probably something like *kʷékʷlos. This evolved over time to be something like *hwehwlą, in Proto-Germanic, the most recent common ancestor of languages like German, English, and Norwegian. This eventually became *hweōl in Old English and wheel today. That was journey that the word *kʷékʷlos took westward to arrive in English as wheel. But how did it arrive in Japanese as jinrikishaw?\nNot all of the Yamnaya people went west into Europe. Some went south into Iran and India, others went east to the edge of Mongolia. We call the earliest of these people the Afanasievo Culture, but we only know them through their archeological remains. One of the things we know about them, however, is that they used carts as early as ~3500 BCE. They are also likely to be the source of a group known as the Tocharians, that lived in the Tarim Basin in modern day Xinjiang, China. They spoke a family of languages known as Tocharian and were producing manuscripts in their languages as late as 500-800 AD. Between the Afanasievans and the Tocharians, there was almost certainly a continuous, cart-using Indo-European presence on the Chinese periphery for roughly 4000 years, a time period including the earliest known presence of wheeled vehicles in China.\nSome of these Indo-European speakers are likely the source of the Old Chinese word for wheeled vehicles, 車, which would have been pronounced *kʰlja around 1200 BC. This evolved into something like *t͡ɕʰia in Middle Chinese. That was borrowed into Japanese as 人力車 jinrikisha, or “human-power cart”, recognizably the same word we use in English today and a cognate with “wheel”.\nTestPAT"
  },
  {
    "objectID": "posts/20230719-getting-around-istanbul/index.html",
    "href": "posts/20230719-getting-around-istanbul/index.html",
    "title": "Getting Around Istanbul",
    "section": "",
    "text": "Summary:\n\nThe metro and ferries are the best public transit options\nGoogle Maps works, but Moovit has much better coverage for ferry routes\nAvoid relying on taxis unless absolutely necessary\nUber calls taxis and you will likely have an excessive wait\nAvoid minibuses (light blue buses on Google Maps)\n\nIf you don’t like my guide, you can read more about getting to and from the airport here\nIf you don’t like my guide, you can read more about public transit here\n\n\nGeneral Information\nIstanbul has a very well-developed public transit system. It spans the Bosphorous Strait to connect both sides of city and connects both passenger airports (IST and SAW) to the city center. Public transit, especially the ferries and metro, are the best way to get around the city due to rush hour traffic. The metro system covers all of the main touristic areas of the city and is easy to use. On weeknights most public transit shuts down around midnight, so plan on staying near your hotel if you want to go out late. Google Maps does a good job of providing routes and even has several privately owned airport bus companies listed. Almost all of the public transit can be accessed using an IstanbulKart that can be purchased from and reloaded at yellow kiosks in metro stations. In tourist areas, you’re more likely to find kiosks that have an English option. Each connection you use will incur a new charge, so make sure your IstanbulKart is loaded up. And importantly, most IstanbulKart machines cannot take bills larger than 100 TL! Each leg of a journey will probably cost ~10TL\n\n\nModes of Transit\n\nMetro\n\n\n\nIstanbul metro map\n\n\nThe metro system in Istanbul is clean and easy to use. It functions just like the metro lines in most major cities. Expect trains every 5-10 min in most cases. Trains run from 6:00 AM to midnight, but there is uninterrupted 24-hour service with trains every 30 min Friday and Saturday night. This should be one of your primary ways of getting around the city. There is only one metro line that crosses the Bosphorous Strait, the Marmaray (gray line). This line is more expensive.\n\n\nFerries\nFerries in Istanbul are fully integrated into the public transit network, so you can use your IstanbulKart to board them. They are very convenient, and should also be one of your primary modes of transportation. They are automatically included in Google Maps routes and marked with a blue boat sign. At many of the ferry stations, there will be several wharfs with different ferries. For the busiest ferries, there can even be two docks running the same route at staggered intervals. Make sure you are getting on the right one by checking the signs! Public ferry schedules can be found here: https://sehirhatlari.istanbul/en/timetables . There are also private ferries (which can still be accessed using your IstanbulKart), but these are not included in Google Maps. Roughly half of the ferries moving on major routes are operated by private companies. If you see a ferry on Google Maps that’s running on the :00 and :30 marks, there is probably another dock nearby with a private ferry that leaves on the :15 and :45 marks. Private ferries are included in the Moovit app.\n\n\nBuses\nThere are three types of buses in Istanbul that might be included in your route.\n\nStandard city buses: These are big yellow and black buses, and they have a yellow bus symbol on Google Maps. You pay when you get on. Most buses will stop running before midnight.\nMetrobuses: These have a beige bus symbol on Google Maps. These buses have their own lanes and move pretty quickly. You pay when you enter the station as if it were a metro.\nMinibuses: These are tiny death traps with no ventilation. They are marked with a light blue bus symbol on Google Maps. I recommend not using them because they only take cash and you have to tell them your destination.\n\n\n\nTaxis\nAvoid taxis unless absolutely necessary. They are notorious for scamming people, often do not speak English, and will not know how to get to your destination. Many taxis are cash only. If you have to take a taxi, make sure the meter is running as soon as you get in the cab, and pull up the route on your phone so that you see if they make any detours. There may be additional fees associated with crossing the bridges, but these should be small (~20 TL).\n\n\nGetting to/from the Airport\nBoth Istanbul airports (IST and SAW) are a ways outside the city, so it can take some time to get to the city center where your hotels probably are.\nThere are several ways you can get to/from the airport. The easiest way is going to be getting your hotel to call you an airport shuttle. Note that the wedding venue (A11 Hotel Bosphorus) provides an airport shuttle. You also might be able to save yourself a few dollars by booking a shuttle yourself with a private shuttle service such as https://airporttransfer.vip/ . This should cost ~€40. I’ve seen good reviews for this service, but I haven’t used it personally. Driving directly to your hotel should take ~45 min, but traffic can add up to an hour if you’re landing during rush hour.\nAnother way is to take an airport bus. There are private companies that offer reliable service between the airport and popular destinations in Istanbul. These run 24/7, but at 30-60 min intervals. The most popular is Havaist, which leaves from the -2 floor of the IST airport https://istanbul-international-airport.com/transportation/bus/ . If you are staying in Uskudar, you can take the Havaist bus to Kadikoy, followed by the metro from Kadikoy to Uskudar. This is two stops, but requires changing lines at the first stop. The total cost of this trip will be ~$7, not including buying an IstanbulKart to use the public transit. You can also take the Havaist bus to Besiktas and take a ferry from Besiktas to Uskudar.\nThe airports also connects directly to the metro system. You can connect to either the historic areas of Istanbul or Uskudar, but it will require several transfers, and take slightly longer than the Havaist bus. You can get to Uskudar by taking the M11-M7-M2-Marmaray route. Most other areas of the city—such as Galata and Eminonu—are accessible via the M2 line without crossing the Bosphorous using the Marmaray. Some of the stations are quite large, and it may not be desirable to lug around a ton of bags."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Daniel Geiszler",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nLearning Pyro for Better Content Sorting\n\n\n\n\n\n\nmachine learning\n\n\npython\n\n\n\n\n\n\n\n\n\nDec 15, 2024\n\n\n14 min\n\n\n\n\n\n\n\nInteresting Etymologies Running List\n\n\n\n\n\n\nlinguistics\n\n\n\n\n\n\n\n\n\nMay 16, 2024\n\n\n1 min\n\n\n\n\n\n\n\nGetting Around Istanbul\n\n\n\n\n\n\nIstanbul\n\n\nTurkey\n\n\npublic transit\n\n\n\n\n\n\n\n\n\nJul 19, 2023\n\n\n6 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Daniel Geiszler",
    "section": "",
    "text": "Hi, I’m Danny 🧬\nI’m an EMBO Postdoctoral Fellow at Istanbul’s Koç University, trying to figure out how to maximize the PTM information we can get out of DIA data using machine learning and Bayesian statistics. My field of study is computational proteomics, with a specialization in post-translational modifications, especially open searches, glycosylation, and chemoproteomics.\nI did my Bioinformatics PhD at the University of Michigan in Alexey Nesvizhskii’s lab where I developed PTM-Shepherd and contributed to FragPipe, as well as helping in several PTM-related statistics and data science projects.\nIf you’re ever up for a friendly chat or potential collaboration, don’t hesitate to reach out."
  },
  {
    "objectID": "posts/20240517-interesting-etymologies/etymologies.html",
    "href": "posts/20240517-interesting-etymologies/etymologies.html",
    "title": "Daniel Geiszler",
    "section": "",
    "text": "This is a running list of etymologies that I think are neat."
  },
  {
    "objectID": "posts/20240517-interesting-etymologies/etymologies.html#temujin",
    "href": "posts/20240517-interesting-etymologies/etymologies.html#temujin",
    "title": "Daniel Geiszler",
    "section": "Temujin",
    "text": "Temujin\nGenghis Khan was just a title; his real name was Temujin. Temujin is a Mongolic name that was probably borrowed from the Proto-Turkic *temürči meaning “blacksmith”. The -ci suffix denotes a person who works with something, in this case *temür, or iron. Modern Turkish’s “demirci”, also meaning “blacksmith”, is a descendent of this word and a cognate to Temujin. These names and their friends were and are still common throughout the region. For example, Timur (also known as Tamerlame), of the Timurid Empire, shares the same root—Timur, like Turkish demir, means iron."
  },
  {
    "objectID": "posts/20240517-interesting-etymologies/etymologies.html#ordu",
    "href": "posts/20240517-interesting-etymologies/etymologies.html#ordu",
    "title": "Daniel Geiszler",
    "section": "Ordu",
    "text": "Ordu\nOrdu is the Turkish word for “army”. It actually has an English cognate, “horde”! Quite a few European languages seem to have picked this word up via contact with Central Asians. The most likely source appears to be Proto-Turkic, which makes sense given the role they played in Central Asian empires. But there’s another cognate to ordu that’s even more interesting: Urdu, the national language of Pakistan. The Mughal Empire of India established Persian as the official language of the empire, and the Hindustani dialect spoken in the military camps came to be referred to as “Zaban-e-Urdu” in Persian, or “language of the army”, eventually being shortened to just “Urdu”."
  },
  {
    "objectID": "posts/20240517-interesting-etymologies/etymologies.html#rickshaw",
    "href": "posts/20240517-interesting-etymologies/etymologies.html#rickshaw",
    "title": "Daniel Geiszler",
    "section": "Rickshaw",
    "text": "Rickshaw\nRickshaws are small, hand-drawn passenger carts that were (and in some places, are) popular in Asia. It comes from the Japanese word 人力車 jinrikisha. But when it entered the English language, it actually already had a cognate, a word that came from the same root: wheel.\nFive thousand years, a group called the Yamnaya used carts and wagons on the Ukrainian Steppe. This group is generally accepted to be the source of the Indo-European Languages—a language family encompassing languages as diverse as English, Persian, and Hindi. Their word for wheel was probably something like *kʷékʷlos. This evolved over time to be something like *hwehwlą, in Proto-Germanic, the most recent common ancestor of languages like German, English, and Norwegian. This eventually became *hweōl in Old English and wheel today. That was journey that the word *kʷékʷlos took westward to arrive in English as wheel. But how did it arrive in Japanese as jinrikishaw?\nNot all of the Yamnaya people went west into Europe. Some went south into Iran and India, others went east to the edge of Mongolia. We call the earliest of these people the Afanasievo Culture, but we only know them through their archeological remains. One of the things we know about them, however, is that they used carts as early as ~3500 BCE. They are also likely to be the source of a group known as the Tocharians, that lived in the Tarim Basin in modern day Xinjiang, China. They spoke a family of languages known as Tocharian and were producing manuscripts in their languages as late as 500-800 AD. Between the Afanasievans and the Tocharians, there was almost certainly a continuous, cart-using Indo-European presence on the Chinese periphery for roughly 4000 years, a time period including the earliest known presence of wheeled vehicles in China.\nSome of these Indo-European speakers are likely the source of the Old Chinese word for wheeled vehicles, 車, which would have been pronounced *kʰlja around 1200 BC. This evolved into something like *t͡ɕʰia in Middle Chinese. That was borrowed into Japanese as 人力車 jinrikisha, or “human-power cart”, recognizably the same word we use in English today and a cognate with “wheel”.\nTestPAT"
  },
  {
    "objectID": "dashboards.html",
    "href": "dashboards.html",
    "title": "Daniel Geiszler",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTraining Dashboard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2024\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "dashboards/20241201-training-dashboard/index.html",
    "href": "dashboards/20241201-training-dashboard/index.html",
    "title": "Training Dashboard",
    "section": "",
    "text": "This is a dashboard I made to track progress in the gym. Because this website is hosted on github-pages, which only allows static content, the dashboard itself automatically deploys on Render whenever there are updates and is embedded here in an iframe. If the formatting here is poor, it can be visited directly. Render will also shut down any apps that are inactive, so it may take a minute to start up once you open this page.\nIf you’re interested in using this yourself, just follow these steps:\n\nRecord your workouts in Google Sheets. I record my workouts here. This sheet contains the minimum columns required for the dashboard to function.\nPublish your workouts to the web. Go to File &gt; Share &gt; Publish to the web on your Google Sheet. Choose Entire Document and select Comma-separated values (.csv) as the format. Click Publish and confirm.\nWhen you open the dashboard, copy-paste your link into the data url field and click “Load Data”.\n\nFeel free to suggest features or make changes yourself. Enjoy!"
  },
  {
    "objectID": "posts/20241215-testing-pyro/index.html",
    "href": "posts/20241215-testing-pyro/index.html",
    "title": "Learning Pyro for Better Content Sorting",
    "section": "",
    "text": "I’ve been looking for a reason to learn to use the Pyro library in Python for Markov Chain Monte Carlo (MCMC) simulations, and I’ve finally found one. This is me documenting how to learn to use it for future reference, and hopefully you’ll be able to get something out of it too.\nHave you ever sorted content on a website by “Top Ranked” or something similar, only do be inundated with a bunch of posts with a 100% rating but only a tiny number of reviews? It can make it frustrating or impossible to find “the best” of something when it’s hiding below hundreds or thousands of other things. If you’re going to rank by the average score for a piece of content, it’s inevitable that you’ll end up with some items near the top of the list that shouldn’t be. This happens because low sample sizes (e.g., a small number of reviews or upvotes) lead to a wide variety of estimates of the content’s “true” rating.\nThankfully, lots of smart companies have come up with better ways to rank their content! Reddit, for example, used to use a confidence interval around the score of the of a post (see the cpdef double _confidence function) to account for uncertainty in its “true” score. This has the effect of penalizing upvoted posts that have a low score with only a handful of upvotes, but it will also boost downvoted posts in the same situation. As the number of votes increases, the confidence in the post’s true rating also increases.\nOther companies seem to have an issue with this. For example, Google Maps has pretty limited options on what you can sort by, and instead only allows you to filter based on certain ranges of average review score. This still leaves the top results polluted by new, fake, or closed restaurants when you’re going out to eat. This isn’t a good system, and I frequently find myself with bad results. You have to go to an entirely different website to get decent results.\nFinding a better estimate of a restaurant’s “true rating” is a good use case for Pyro, a probabilistic programming language thats uses PyTorch. Pyro make it easy to find a restaurant’s “true rating” (posterior probability) given its current ratings (likelihood) and some assumptions about what its true rating is likely to be before any reviews are given (prior probability). These problems can be solved using MCMC simulations to estimate the posterior probability. PyTorch is supposed to make these sorts of problems easy, so I’m going to use it to estimate the posterior probabilities of some content and learn how to use Pyro along the way.\nInstalling PyTorch isn’t as simple as most other python packages, so I recommend looking at their website to do it (https://pytorch.org/). Beyond that, you’ll also need pandas and the pyro package (https://pyro.ai/).\n\n# import packages\n\nimport torch\nimport pyro\nimport pyro.distributions as dist\nimport pandas as pd\n\nfrom pyro.infer import MCMC, NUTS, SVI, Trace_ELBO\nfrom pyro.optim import Adam\n\nIf you installed PyTorch correctly and you have an nVidia GPU, you can run this to see if your GPU is available for PyTorch to use. This workbook should still work even if this isn’t true, instead running the simulations on your CPU. The first few will run on the default device, but I’ll switch to my GPU later.\n\nif torch.cuda.is_available():\n    print(\"CUDA is available. GPU is ready to be used.\")\nelse:\n    print(\"CUDA is not available. Running on CPU.\")\n\nCUDA is available. GPU is ready to be used.\n\n\nAs a toy example, let’s consider a restaurant or some other piece of content that has a single upvote in an upvote/downvote rating system. This will run on the default device regardless of your GPU setup.\n\n# Data: 1 thumb up out of 1 observation\ndata = torch.tensor([1.])\n\nWe first need to define a model that PyTorch will simulate.\n\nThe pyro.sample function here is given two arguments: the name of your sample and the prior distribution. In this case, we use the Beta(1,1) distribution as our prior. This draws a sample from the Beta(1,1) distribution for our prior. The beta distribution is a common prior when estimating probabilities because of both the posterior and the prior are defined over [0,1]. It is also a conjugate prior for the Binomial distribution, which is the distribution for a series of up-down votes. The Beta(1,1) is a uniform distribution, which indicates we have no information about the prior probability. In practice, Betas tend to be used more than Uniforms due to their flexibility, but the results should be the same regardless. It is also easy to interpret in our case because the Beta(a,b) parameters a and b correspond to pseudocounts for upvotes and downvotes for our content. This will come in handy later.\nThe pyro.plate function indicates that all of the observations are IID, and again takes two arguments: a name and the number of observations. We then use the pyro.sample function again, but this time the probability of success (in this case, an upvoted restaurants) is given by the the probability from the first step, and our observed data is used as our evidence.\n\n\n# Define the model\ndef beta_model(data):\n    # Prior distribution for the probability of a thumb up\n    prob_thumb_up = pyro.sample(\"prob_thumb_up\", dist.Beta(1, 1))\n    # Observing the data\n    with pyro.plate(\"data\", len(data)):\n        pyro.sample(\"obs\", dist.Bernoulli(prob_thumb_up), obs=data)\n\nTo simulate our posterior, we use NUTS (No U-turn Sampler). We then run our MCMC method to extract all of the posterior simulations. The NUTS sampler starts off slow and not giving useful information at the beginning, so we throw out the first warmup_steps.\n\n# Run sampling\nnuts_kernel = NUTS(beta_model)\nmcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=200)\nmcmc.run(data)\n\nWarmup:   0%|          | 0/300 [00:00, ?it/s]Warmup:   6%|▋         | 19/300 [00:00, 190.00it/s, step size=1.25e+00, acc. prob=0.751]Warmup:  15%|█▌        | 45/300 [00:00, 228.50it/s, step size=1.65e+00, acc. prob=0.777]Warmup:  25%|██▍       | 74/300 [00:00, 256.06it/s, step size=1.22e+00, acc. prob=0.782]Warmup:  36%|███▌      | 108/300 [00:00, 287.31it/s, step size=4.48e-01, acc. prob=0.777]Warmup:  48%|████▊     | 145/300 [00:00, 309.93it/s, step size=1.46e+00, acc. prob=0.783]Warmup:  59%|█████▊    | 176/300 [00:00, 306.81it/s, step size=6.46e-01, acc. prob=0.781]Sample:  69%|██████▉   | 208/300 [00:00, 309.12it/s, step size=1.04e+00, acc. prob=0.915]Sample:  83%|████████▎ | 249/300 [00:00, 338.71it/s, step size=1.04e+00, acc. prob=0.892]Sample:  97%|█████████▋| 290/300 [00:00, 357.34it/s, step size=1.04e+00, acc. prob=0.897]Sample: 100%|██████████| 300/300 [00:00, 317.22it/s, step size=1.04e+00, acc. prob=0.899]\n\n\nNow that our 100 samples have run in ~1 second, we can see what our posterior distribution looks like.\n\n# Extract samples\nsamples = mcmc.get_samples()\nprob_thumb_up_samples = samples['prob_thumb_up']\nprint(samples)\n\n# Make histogram of samples\nsamples_df = pd.DataFrame(samples)\nsamples_df.hist()\n\n{'prob_thumb_up': tensor([0.3754, 0.6458, 0.6215, 0.6673, 0.6825, 0.6825, 0.9285, 0.9551, 0.4132,\n        0.5960, 0.6367, 0.8789, 0.9242, 0.9909, 0.9961, 0.8353, 0.7794, 0.4894,\n        0.4894, 0.7527, 0.9925, 0.9846, 0.9204, 0.7989, 0.7989, 0.7631, 0.8936,\n        0.5362, 0.8810, 0.2876, 0.2743, 0.4360, 0.2989, 0.2143, 0.3124, 0.5030,\n        0.6797, 0.7506, 0.7535, 0.3841, 0.4743, 0.4743, 0.6214, 0.6214, 0.8456,\n        0.6840, 0.6840, 0.7425, 0.9353, 0.8336, 0.8336, 0.8424, 0.7697, 0.6447,\n        0.6352, 0.6352, 0.9111, 0.8721, 0.8918, 0.8699, 0.9374, 0.4371, 0.1400,\n        0.2007, 0.3737, 0.8435, 0.7996, 0.2103, 0.6420, 0.9197, 0.9983, 0.9518,\n        0.6668, 0.5557, 0.9482, 0.9872, 0.7521, 0.1814, 0.2036, 0.6258, 0.2069,\n        0.3711, 0.2595, 0.4180, 0.5293, 0.9503, 0.8273, 0.3834, 0.6513, 0.6072,\n        0.5900, 0.5900, 0.6927, 0.5713, 0.6686, 0.8526, 0.4008, 0.1775, 0.6810,\n        0.5947])}\n\n\narray([[&lt;Axes: title={'center': 'prob_thumb_up'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\nOur probability distribution looks like it’s multimodal, when it should be unimodal. That probably means the model didn’t converge. Let’s try upping the number of samples we use to see if we can get a better behaved distribution.\n\n# Run sampling\nnuts_kernel = NUTS(beta_model)\nmcmc = MCMC(nuts_kernel, num_samples=10000, warmup_steps=200)\nmcmc.run(data)\n\n# Extract samples\nsamples = mcmc.get_samples()\nprob_thumb_up_samples = samples['prob_thumb_up']\nprint(samples)\n\n# Make histogram of samples\nsamples_df = pd.DataFrame(samples)\nsamples_df.hist()\n\nWarmup:   0%|          | 0/10200 [00:00, ?it/s]Warmup:   0%|          | 27/10200 [00:00, 264.69it/s, step size=2.01e+00, acc. prob=0.770]Warmup:   1%|          | 58/10200 [00:00, 290.19it/s, step size=3.27e+00, acc. prob=0.786]Warmup:   1%|          | 91/10200 [00:00, 306.86it/s, step size=1.99e+00, acc. prob=0.787]Warmup:   1%|▏         | 133/10200 [00:00, 348.50it/s, step size=4.65e-01, acc. prob=0.782]Warmup:   2%|▏         | 168/10200 [00:00, 335.00it/s, step size=2.79e+00, acc. prob=0.780]Sample:   2%|▏         | 211/10200 [00:00, 365.04it/s, step size=1.62e+00, acc. prob=0.838]Sample:   2%|▏         | 250/10200 [00:00, 373.00it/s, step size=1.62e+00, acc. prob=0.869]Sample:   3%|▎         | 290/10200 [00:00, 379.08it/s, step size=1.62e+00, acc. prob=0.890]Sample:   3%|▎         | 330/10200 [00:00, 384.61it/s, step size=1.62e+00, acc. prob=0.890]Sample:   4%|▎         | 376/10200 [00:01, 405.12it/s, step size=1.62e+00, acc. prob=0.901]Sample:   4%|▍         | 418/10200 [00:01, 409.61it/s, step size=1.62e+00, acc. prob=0.897]Sample:   5%|▍         | 462/10200 [00:01, 415.74it/s, step size=1.62e+00, acc. prob=0.901]Sample:   5%|▍         | 504/10200 [00:01, 407.25it/s, step size=1.62e+00, acc. prob=0.897]Sample:   5%|▌         | 545/10200 [00:01, 400.98it/s, step size=1.62e+00, acc. prob=0.899]Sample:   6%|▌         | 587/10200 [00:01, 405.88it/s, step size=1.62e+00, acc. prob=0.893]Sample:   6%|▌         | 628/10200 [00:01, 398.88it/s, step size=1.62e+00, acc. prob=0.890]Sample:   7%|▋         | 668/10200 [00:01, 381.39it/s, step size=1.62e+00, acc. prob=0.891]Sample:   7%|▋         | 707/10200 [00:01, 376.34it/s, step size=1.62e+00, acc. prob=0.894]Sample:   7%|▋         | 749/10200 [00:01, 386.58it/s, step size=1.62e+00, acc. prob=0.892]Sample:   8%|▊         | 793/10200 [00:02, 400.26it/s, step size=1.62e+00, acc. prob=0.889]Sample:   8%|▊         | 834/10200 [00:02, 393.90it/s, step size=1.62e+00, acc. prob=0.887]Sample:   9%|▊         | 874/10200 [00:02, 395.66it/s, step size=1.62e+00, acc. prob=0.887]Sample:   9%|▉         | 915/10200 [00:02, 399.25it/s, step size=1.62e+00, acc. prob=0.888]Sample:   9%|▉         | 955/10200 [00:02, 395.89it/s, step size=1.62e+00, acc. prob=0.888]Sample:  10%|▉         | 1002/10200 [00:02, 416.54it/s, step size=1.62e+00, acc. prob=0.889]Sample:  10%|█         | 1044/10200 [00:02, 405.60it/s, step size=1.62e+00, acc. prob=0.889]Sample:  11%|█         | 1085/10200 [00:02, 405.69it/s, step size=1.62e+00, acc. prob=0.887]Sample:  11%|█         | 1126/10200 [00:02, 397.68it/s, step size=1.62e+00, acc. prob=0.889]Sample:  11%|█▏        | 1166/10200 [00:03, 394.01it/s, step size=1.62e+00, acc. prob=0.889]Sample:  12%|█▏        | 1206/10200 [00:03, 381.33it/s, step size=1.62e+00, acc. prob=0.889]Sample:  12%|█▏        | 1245/10200 [00:03, 378.52it/s, step size=1.62e+00, acc. prob=0.890]Sample:  13%|█▎        | 1291/10200 [00:03, 400.77it/s, step size=1.62e+00, acc. prob=0.892]Sample:  13%|█▎        | 1332/10200 [00:03, 397.67it/s, step size=1.62e+00, acc. prob=0.893]Sample:  13%|█▎        | 1372/10200 [00:03, 397.19it/s, step size=1.62e+00, acc. prob=0.893]Sample:  14%|█▍        | 1419/10200 [00:03, 418.31it/s, step size=1.62e+00, acc. prob=0.893]Sample:  14%|█▍        | 1467/10200 [00:03, 435.98it/s, step size=1.62e+00, acc. prob=0.893]Sample:  15%|█▍        | 1511/10200 [00:03, 428.88it/s, step size=1.62e+00, acc. prob=0.892]Sample:  15%|█▌        | 1554/10200 [00:03, 422.55it/s, step size=1.62e+00, acc. prob=0.893]Sample:  16%|█▌        | 1597/10200 [00:04, 413.15it/s, step size=1.62e+00, acc. prob=0.893]Sample:  16%|█▌        | 1639/10200 [00:04, 412.72it/s, step size=1.62e+00, acc. prob=0.893]Sample:  16%|█▋        | 1681/10200 [00:04, 408.30it/s, step size=1.62e+00, acc. prob=0.894]Sample:  17%|█▋        | 1722/10200 [00:04, 400.66it/s, step size=1.62e+00, acc. prob=0.893]Sample:  17%|█▋        | 1763/10200 [00:04, 398.74it/s, step size=1.62e+00, acc. prob=0.893]Sample:  18%|█▊        | 1803/10200 [00:04, 399.10it/s, step size=1.62e+00, acc. prob=0.894]Sample:  18%|█▊        | 1845/10200 [00:04, 402.87it/s, step size=1.62e+00, acc. prob=0.893]Sample:  19%|█▊        | 1889/10200 [00:04, 411.36it/s, step size=1.62e+00, acc. prob=0.894]Sample:  19%|█▉        | 1931/10200 [00:04, 413.90it/s, step size=1.62e+00, acc. prob=0.894]Sample:  19%|█▉        | 1973/10200 [00:04, 398.03it/s, step size=1.62e+00, acc. prob=0.895]Sample:  20%|█▉        | 2016/10200 [00:05, 407.23it/s, step size=1.62e+00, acc. prob=0.895]Sample:  20%|██        | 2057/10200 [00:05, 406.21it/s, step size=1.62e+00, acc. prob=0.895]Sample:  21%|██        | 2101/10200 [00:05, 412.50it/s, step size=1.62e+00, acc. prob=0.895]Sample:  21%|██        | 2143/10200 [00:05, 412.59it/s, step size=1.62e+00, acc. prob=0.894]Sample:  21%|██▏       | 2185/10200 [00:05, 388.49it/s, step size=1.62e+00, acc. prob=0.894]Sample:  22%|██▏       | 2225/10200 [00:05, 387.36it/s, step size=1.62e+00, acc. prob=0.894]Sample:  22%|██▏       | 2264/10200 [00:05, 377.98it/s, step size=1.62e+00, acc. prob=0.894]Sample:  23%|██▎       | 2305/10200 [00:05, 385.98it/s, step size=1.62e+00, acc. prob=0.894]Sample:  23%|██▎       | 2345/10200 [00:05, 388.91it/s, step size=1.62e+00, acc. prob=0.893]Sample:  23%|██▎       | 2385/10200 [00:06, 382.12it/s, step size=1.62e+00, acc. prob=0.893]Sample:  24%|██▍       | 2425/10200 [00:06, 387.26it/s, step size=1.62e+00, acc. prob=0.893]Sample:  24%|██▍       | 2466/10200 [00:06, 393.28it/s, step size=1.62e+00, acc. prob=0.893]Sample:  25%|██▍       | 2506/10200 [00:06, 380.72it/s, step size=1.62e+00, acc. prob=0.893]Sample:  25%|██▍       | 2546/10200 [00:06, 385.25it/s, step size=1.62e+00, acc. prob=0.893]Sample:  25%|██▌       | 2585/10200 [00:06, 380.00it/s, step size=1.62e+00, acc. prob=0.893]Sample:  26%|██▌       | 2627/10200 [00:06, 391.60it/s, step size=1.62e+00, acc. prob=0.893]Sample:  26%|██▌       | 2667/10200 [00:06, 385.03it/s, step size=1.62e+00, acc. prob=0.893]Sample:  27%|██▋       | 2706/10200 [00:06, 384.66it/s, step size=1.62e+00, acc. prob=0.893]Sample:  27%|██▋       | 2749/10200 [00:06, 394.45it/s, step size=1.62e+00, acc. prob=0.893]Sample:  27%|██▋       | 2797/10200 [00:07, 419.48it/s, step size=1.62e+00, acc. prob=0.894]Sample:  28%|██▊       | 2840/10200 [00:07, 409.83it/s, step size=1.62e+00, acc. prob=0.893]Sample:  28%|██▊       | 2882/10200 [00:07, 409.22it/s, step size=1.62e+00, acc. prob=0.893]Sample:  29%|██▊       | 2926/10200 [00:07, 416.97it/s, step size=1.62e+00, acc. prob=0.893]Sample:  29%|██▉       | 2969/10200 [00:07, 419.56it/s, step size=1.62e+00, acc. prob=0.894]Sample:  30%|██▉       | 3015/10200 [00:07, 427.52it/s, step size=1.62e+00, acc. prob=0.895]Sample:  30%|██▉       | 3058/10200 [00:07, 411.31it/s, step size=1.62e+00, acc. prob=0.894]Sample:  30%|███       | 3100/10200 [00:07, 401.12it/s, step size=1.62e+00, acc. prob=0.895]Sample:  31%|███       | 3141/10200 [00:07, 372.85it/s, step size=1.62e+00, acc. prob=0.894]Sample:  31%|███       | 3179/10200 [00:08, 367.77it/s, step size=1.62e+00, acc. prob=0.894]Sample:  32%|███▏      | 3217/10200 [00:08, 366.55it/s, step size=1.62e+00, acc. prob=0.895]Sample:  32%|███▏      | 3254/10200 [00:08, 352.66it/s, step size=1.62e+00, acc. prob=0.895]Sample:  32%|███▏      | 3290/10200 [00:08, 349.84it/s, step size=1.62e+00, acc. prob=0.895]Sample:  33%|███▎      | 3326/10200 [00:08, 340.25it/s, step size=1.62e+00, acc. prob=0.895]Sample:  33%|███▎      | 3361/10200 [00:08, 334.33it/s, step size=1.62e+00, acc. prob=0.895]Sample:  33%|███▎      | 3395/10200 [00:08, 322.38it/s, step size=1.62e+00, acc. prob=0.894]Sample:  34%|███▎      | 3428/10200 [00:08, 324.49it/s, step size=1.62e+00, acc. prob=0.894]Sample:  34%|███▍      | 3468/10200 [00:08, 343.01it/s, step size=1.62e+00, acc. prob=0.894]Sample:  34%|███▍      | 3509/10200 [00:09, 362.22it/s, step size=1.62e+00, acc. prob=0.893]Sample:  35%|███▍      | 3548/10200 [00:09, 368.17it/s, step size=1.62e+00, acc. prob=0.893]Sample:  35%|███▌      | 3585/10200 [00:09, 363.85it/s, step size=1.62e+00, acc. prob=0.893]Sample:  36%|███▌      | 3623/10200 [00:09, 366.43it/s, step size=1.62e+00, acc. prob=0.893]Sample:  36%|███▌      | 3665/10200 [00:09, 378.48it/s, step size=1.62e+00, acc. prob=0.893]Sample:  36%|███▋      | 3703/10200 [00:09, 371.31it/s, step size=1.62e+00, acc. prob=0.893]Sample:  37%|███▋      | 3742/10200 [00:09, 375.11it/s, step size=1.62e+00, acc. prob=0.893]Sample:  37%|███▋      | 3784/10200 [00:09, 387.12it/s, step size=1.62e+00, acc. prob=0.893]Sample:  37%|███▋      | 3823/10200 [00:09, 379.06it/s, step size=1.62e+00, acc. prob=0.893]Sample:  38%|███▊      | 3865/10200 [00:09, 388.72it/s, step size=1.62e+00, acc. prob=0.893]Sample:  38%|███▊      | 3904/10200 [00:10, 369.64it/s, step size=1.62e+00, acc. prob=0.894]Sample:  39%|███▊      | 3942/10200 [00:10, 355.84it/s, step size=1.62e+00, acc. prob=0.893]Sample:  39%|███▉      | 3978/10200 [00:10, 335.44it/s, step size=1.62e+00, acc. prob=0.893]Sample:  39%|███▉      | 4014/10200 [00:10, 339.37it/s, step size=1.62e+00, acc. prob=0.893]Sample:  40%|███▉      | 4049/10200 [00:10, 339.49it/s, step size=1.62e+00, acc. prob=0.893]Sample:  40%|████      | 4084/10200 [00:10, 340.54it/s, step size=1.62e+00, acc. prob=0.893]Sample:  40%|████      | 4119/10200 [00:10, 337.02it/s, step size=1.62e+00, acc. prob=0.893]Sample:  41%|████      | 4153/10200 [00:10, 266.50it/s, step size=1.62e+00, acc. prob=0.893]Sample:  41%|████      | 4189/10200 [00:11, 287.93it/s, step size=1.62e+00, acc. prob=0.893]Sample:  41%|████▏     | 4224/10200 [00:11, 302.37it/s, step size=1.62e+00, acc. prob=0.894]Sample:  42%|████▏     | 4260/10200 [00:11, 316.29it/s, step size=1.62e+00, acc. prob=0.893]Sample:  42%|████▏     | 4299/10200 [00:11, 335.70it/s, step size=1.62e+00, acc. prob=0.894]Sample:  43%|████▎     | 4341/10200 [00:11, 357.48it/s, step size=1.62e+00, acc. prob=0.893]Sample:  43%|████▎     | 4378/10200 [00:11, 357.99it/s, step size=1.62e+00, acc. prob=0.893]Sample:  43%|████▎     | 4420/10200 [00:11, 372.65it/s, step size=1.62e+00, acc. prob=0.894]Sample:  44%|████▎     | 4460/10200 [00:11, 373.01it/s, step size=1.62e+00, acc. prob=0.894]Sample:  44%|████▍     | 4498/10200 [00:11, 368.64it/s, step size=1.62e+00, acc. prob=0.894]Sample:  44%|████▍     | 4536/10200 [00:11, 354.53it/s, step size=1.62e+00, acc. prob=0.894]Sample:  45%|████▍     | 4574/10200 [00:12, 359.59it/s, step size=1.62e+00, acc. prob=0.894]Sample:  45%|████▌     | 4616/10200 [00:12, 375.56it/s, step size=1.62e+00, acc. prob=0.894]Sample:  46%|████▌     | 4660/10200 [00:12, 390.82it/s, step size=1.62e+00, acc. prob=0.894]Sample:  46%|████▌     | 4700/10200 [00:12, 385.63it/s, step size=1.62e+00, acc. prob=0.894]Sample:  46%|████▋     | 4740/10200 [00:12, 386.44it/s, step size=1.62e+00, acc. prob=0.894]Sample:  47%|████▋     | 4781/10200 [00:12, 392.15it/s, step size=1.62e+00, acc. prob=0.894]Sample:  47%|████▋     | 4821/10200 [00:12, 383.22it/s, step size=1.62e+00, acc. prob=0.894]Sample:  48%|████▊     | 4860/10200 [00:12, 365.14it/s, step size=1.62e+00, acc. prob=0.893]Sample:  48%|████▊     | 4897/10200 [00:12, 359.43it/s, step size=1.62e+00, acc. prob=0.893]Sample:  48%|████▊     | 4938/10200 [00:13, 373.72it/s, step size=1.62e+00, acc. prob=0.893]Sample:  49%|████▉     | 4980/10200 [00:13, 385.92it/s, step size=1.62e+00, acc. prob=0.893]Sample:  49%|████▉     | 5019/10200 [00:13, 374.54it/s, step size=1.62e+00, acc. prob=0.893]Sample:  50%|████▉     | 5057/10200 [00:13, 366.65it/s, step size=1.62e+00, acc. prob=0.893]Sample:  50%|████▉     | 5094/10200 [00:13, 362.43it/s, step size=1.62e+00, acc. prob=0.893]Sample:  50%|█████     | 5133/10200 [00:13, 368.98it/s, step size=1.62e+00, acc. prob=0.893]Sample:  51%|█████     | 5174/10200 [00:13, 377.58it/s, step size=1.62e+00, acc. prob=0.893]Sample:  51%|█████     | 5217/10200 [00:13, 390.56it/s, step size=1.62e+00, acc. prob=0.892]Sample:  52%|█████▏    | 5257/10200 [00:13, 386.54it/s, step size=1.62e+00, acc. prob=0.892]Sample:  52%|█████▏    | 5296/10200 [00:13, 387.54it/s, step size=1.62e+00, acc. prob=0.892]Sample:  52%|█████▏    | 5335/10200 [00:14, 377.19it/s, step size=1.62e+00, acc. prob=0.892]Sample:  53%|█████▎    | 5373/10200 [00:14, 373.24it/s, step size=1.62e+00, acc. prob=0.892]Sample:  53%|█████▎    | 5419/10200 [00:14, 398.39it/s, step size=1.62e+00, acc. prob=0.892]Sample:  54%|█████▎    | 5463/10200 [00:14, 408.56it/s, step size=1.62e+00, acc. prob=0.892]Sample:  54%|█████▍    | 5504/10200 [00:14, 405.95it/s, step size=1.62e+00, acc. prob=0.892]Sample:  54%|█████▍    | 5545/10200 [00:14, 407.14it/s, step size=1.62e+00, acc. prob=0.892]Sample:  55%|█████▍    | 5586/10200 [00:14, 404.40it/s, step size=1.62e+00, acc. prob=0.892]Sample:  55%|█████▌    | 5627/10200 [00:14, 404.86it/s, step size=1.62e+00, acc. prob=0.892]Sample:  56%|█████▌    | 5668/10200 [00:14, 395.84it/s, step size=1.62e+00, acc. prob=0.892]Sample:  56%|█████▌    | 5708/10200 [00:14, 386.90it/s, step size=1.62e+00, acc. prob=0.892]Sample:  56%|█████▋    | 5747/10200 [00:15, 386.67it/s, step size=1.62e+00, acc. prob=0.892]Sample:  57%|█████▋    | 5790/10200 [00:15, 396.56it/s, step size=1.62e+00, acc. prob=0.892]Sample:  57%|█████▋    | 5830/10200 [00:15, 389.59it/s, step size=1.62e+00, acc. prob=0.892]Sample:  58%|█████▊    | 5876/10200 [00:15, 407.67it/s, step size=1.62e+00, acc. prob=0.892]Sample:  58%|█████▊    | 5917/10200 [00:15, 405.42it/s, step size=1.62e+00, acc. prob=0.892]Sample:  58%|█████▊    | 5963/10200 [00:15, 420.17it/s, step size=1.62e+00, acc. prob=0.892]Sample:  59%|█████▉    | 6006/10200 [00:15, 421.46it/s, step size=1.62e+00, acc. prob=0.892]Sample:  59%|█████▉    | 6049/10200 [00:15, 409.55it/s, step size=1.62e+00, acc. prob=0.892]Sample:  60%|█████▉    | 6091/10200 [00:15, 386.82it/s, step size=1.62e+00, acc. prob=0.893]Sample:  60%|██████    | 6130/10200 [00:16, 373.11it/s, step size=1.62e+00, acc. prob=0.893]Sample:  60%|██████    | 6171/10200 [00:16, 382.77it/s, step size=1.62e+00, acc. prob=0.893]Sample:  61%|██████    | 6210/10200 [00:16, 376.29it/s, step size=1.62e+00, acc. prob=0.893]Sample:  61%|██████▏   | 6248/10200 [00:16, 369.98it/s, step size=1.62e+00, acc. prob=0.893]Sample:  62%|██████▏   | 6290/10200 [00:16, 382.04it/s, step size=1.62e+00, acc. prob=0.893]Sample:  62%|██████▏   | 6330/10200 [00:16, 382.81it/s, step size=1.62e+00, acc. prob=0.893]Sample:  62%|██████▎   | 6375/10200 [00:16, 399.90it/s, step size=1.62e+00, acc. prob=0.893]Sample:  63%|██████▎   | 6416/10200 [00:16, 401.27it/s, step size=1.62e+00, acc. prob=0.893]Sample:  63%|██████▎   | 6458/10200 [00:16, 406.29it/s, step size=1.62e+00, acc. prob=0.893]Sample:  64%|██████▎   | 6500/10200 [00:16, 408.95it/s, step size=1.62e+00, acc. prob=0.893]Sample:  64%|██████▍   | 6541/10200 [00:17, 404.48it/s, step size=1.62e+00, acc. prob=0.894]Sample:  65%|██████▍   | 6582/10200 [00:17, 404.25it/s, step size=1.62e+00, acc. prob=0.894]Sample:  65%|██████▍   | 6624/10200 [00:17, 404.13it/s, step size=1.62e+00, acc. prob=0.894]Sample:  65%|██████▌   | 6666/10200 [00:17, 408.36it/s, step size=1.62e+00, acc. prob=0.894]Sample:  66%|██████▌   | 6707/10200 [00:17, 406.43it/s, step size=1.62e+00, acc. prob=0.894]Sample:  66%|██████▌   | 6750/10200 [00:17, 410.97it/s, step size=1.62e+00, acc. prob=0.894]Sample:  67%|██████▋   | 6792/10200 [00:17, 395.57it/s, step size=1.62e+00, acc. prob=0.894]Sample:  67%|██████▋   | 6832/10200 [00:17, 388.73it/s, step size=1.62e+00, acc. prob=0.893]Sample:  67%|██████▋   | 6871/10200 [00:17, 386.88it/s, step size=1.62e+00, acc. prob=0.893]Sample:  68%|██████▊   | 6912/10200 [00:18, 391.31it/s, step size=1.62e+00, acc. prob=0.893]Sample:  68%|██████▊   | 6955/10200 [00:18, 402.22it/s, step size=1.62e+00, acc. prob=0.893]Sample:  69%|██████▊   | 7001/10200 [00:18, 416.09it/s, step size=1.62e+00, acc. prob=0.893]Sample:  69%|██████▉   | 7043/10200 [00:18, 410.61it/s, step size=1.62e+00, acc. prob=0.894]Sample:  69%|██████▉   | 7085/10200 [00:18, 393.50it/s, step size=1.62e+00, acc. prob=0.893]Sample:  70%|██████▉   | 7125/10200 [00:18, 389.62it/s, step size=1.62e+00, acc. prob=0.894]Sample:  70%|███████   | 7168/10200 [00:18, 397.76it/s, step size=1.62e+00, acc. prob=0.894]Sample:  71%|███████   | 7212/10200 [00:18, 406.48it/s, step size=1.62e+00, acc. prob=0.894]Sample:  71%|███████   | 7253/10200 [00:18, 384.11it/s, step size=1.62e+00, acc. prob=0.894]Sample:  71%|███████▏  | 7292/10200 [00:18, 378.33it/s, step size=1.62e+00, acc. prob=0.894]Sample:  72%|███████▏  | 7331/10200 [00:19, 371.14it/s, step size=1.62e+00, acc. prob=0.894]Sample:  72%|███████▏  | 7372/10200 [00:19, 379.37it/s, step size=1.62e+00, acc. prob=0.894]Sample:  73%|███████▎  | 7411/10200 [00:19, 378.17it/s, step size=1.62e+00, acc. prob=0.894]Sample:  73%|███████▎  | 7449/10200 [00:19, 365.05it/s, step size=1.62e+00, acc. prob=0.894]Sample:  73%|███████▎  | 7489/10200 [00:19, 371.80it/s, step size=1.62e+00, acc. prob=0.894]Sample:  74%|███████▍  | 7531/10200 [00:19, 385.61it/s, step size=1.62e+00, acc. prob=0.894]Sample:  74%|███████▍  | 7574/10200 [00:19, 397.13it/s, step size=1.62e+00, acc. prob=0.894]Sample:  75%|███████▍  | 7618/10200 [00:19, 406.61it/s, step size=1.62e+00, acc. prob=0.894]Sample:  75%|███████▌  | 7659/10200 [00:19, 404.05it/s, step size=1.62e+00, acc. prob=0.894]Sample:  76%|███████▌  | 7703/10200 [00:20, 413.38it/s, step size=1.62e+00, acc. prob=0.894]Sample:  76%|███████▌  | 7745/10200 [00:20, 411.69it/s, step size=1.62e+00, acc. prob=0.894]Sample:  76%|███████▋  | 7787/10200 [00:20, 409.25it/s, step size=1.62e+00, acc. prob=0.894]Sample:  77%|███████▋  | 7837/10200 [00:20, 433.35it/s, step size=1.62e+00, acc. prob=0.894]Sample:  77%|███████▋  | 7881/10200 [00:20, 427.75it/s, step size=1.62e+00, acc. prob=0.894]Sample:  78%|███████▊  | 7924/10200 [00:20, 419.82it/s, step size=1.62e+00, acc. prob=0.894]Sample:  78%|███████▊  | 7967/10200 [00:20, 400.67it/s, step size=1.62e+00, acc. prob=0.894]Sample:  79%|███████▊  | 8008/10200 [00:20, 402.17it/s, step size=1.62e+00, acc. prob=0.894]Sample:  79%|███████▉  | 8049/10200 [00:20, 398.63it/s, step size=1.62e+00, acc. prob=0.894]Sample:  79%|███████▉  | 8089/10200 [00:20, 397.95it/s, step size=1.62e+00, acc. prob=0.894]Sample:  80%|███████▉  | 8129/10200 [00:21, 392.84it/s, step size=1.62e+00, acc. prob=0.894]Sample:  80%|████████  | 8169/10200 [00:21, 392.05it/s, step size=1.62e+00, acc. prob=0.894]Sample:  80%|████████  | 8210/10200 [00:21, 396.96it/s, step size=1.62e+00, acc. prob=0.894]Sample:  81%|████████  | 8250/10200 [00:21, 395.53it/s, step size=1.62e+00, acc. prob=0.894]Sample:  81%|████████▏ | 8290/10200 [00:21, 389.63it/s, step size=1.62e+00, acc. prob=0.894]Sample:  82%|████████▏ | 8332/10200 [00:21, 397.35it/s, step size=1.62e+00, acc. prob=0.894]Sample:  82%|████████▏ | 8374/10200 [00:21, 404.00it/s, step size=1.62e+00, acc. prob=0.894]Sample:  82%|████████▎ | 8415/10200 [00:21, 386.35it/s, step size=1.62e+00, acc. prob=0.894]Sample:  83%|████████▎ | 8456/10200 [00:21, 389.77it/s, step size=1.62e+00, acc. prob=0.894]Sample:  83%|████████▎ | 8499/10200 [00:22, 400.26it/s, step size=1.62e+00, acc. prob=0.894]Sample:  84%|████████▎ | 8540/10200 [00:22, 397.67it/s, step size=1.62e+00, acc. prob=0.894]Sample:  84%|████████▍ | 8581/10200 [00:22, 397.32it/s, step size=1.62e+00, acc. prob=0.894]Sample:  85%|████████▍ | 8623/10200 [00:22, 401.59it/s, step size=1.62e+00, acc. prob=0.893]Sample:  85%|████████▍ | 8664/10200 [00:22, 399.98it/s, step size=1.62e+00, acc. prob=0.893]Sample:  85%|████████▌ | 8708/10200 [00:22, 409.31it/s, step size=1.62e+00, acc. prob=0.894]Sample:  86%|████████▌ | 8753/10200 [00:22, 421.26it/s, step size=1.62e+00, acc. prob=0.894]Sample:  86%|████████▌ | 8796/10200 [00:22, 414.05it/s, step size=1.62e+00, acc. prob=0.894]Sample:  87%|████████▋ | 8838/10200 [00:22, 409.70it/s, step size=1.62e+00, acc. prob=0.894]Sample:  87%|████████▋ | 8880/10200 [00:22, 401.12it/s, step size=1.62e+00, acc. prob=0.894]Sample:  88%|████████▊ | 8930/10200 [00:23, 427.69it/s, step size=1.62e+00, acc. prob=0.894]Sample:  88%|████████▊ | 8973/10200 [00:23, 412.68it/s, step size=1.62e+00, acc. prob=0.894]Sample:  88%|████████▊ | 9015/10200 [00:23, 399.82it/s, step size=1.62e+00, acc. prob=0.894]Sample:  89%|████████▉ | 9056/10200 [00:23, 388.44it/s, step size=1.62e+00, acc. prob=0.894]Sample:  89%|████████▉ | 9098/10200 [00:23, 393.97it/s, step size=1.62e+00, acc. prob=0.894]Sample:  90%|████████▉ | 9140/10200 [00:23, 397.96it/s, step size=1.62e+00, acc. prob=0.894]Sample:  90%|█████████ | 9185/10200 [00:23, 410.54it/s, step size=1.62e+00, acc. prob=0.894]Sample:  90%|█████████ | 9227/10200 [00:23, 410.24it/s, step size=1.62e+00, acc. prob=0.894]Sample:  91%|█████████ | 9273/10200 [00:23, 422.27it/s, step size=1.62e+00, acc. prob=0.894]Sample:  91%|█████████▏| 9317/10200 [00:24, 426.21it/s, step size=1.62e+00, acc. prob=0.894]Sample:  92%|█████████▏| 9360/10200 [00:24, 397.68it/s, step size=1.62e+00, acc. prob=0.893]Sample:  92%|█████████▏| 9403/10200 [00:24, 403.91it/s, step size=1.62e+00, acc. prob=0.893]Sample:  93%|█████████▎| 9444/10200 [00:24, 399.28it/s, step size=1.62e+00, acc. prob=0.893]Sample:  93%|█████████▎| 9485/10200 [00:24, 391.17it/s, step size=1.62e+00, acc. prob=0.893]Sample:  93%|█████████▎| 9529/10200 [00:24, 404.61it/s, step size=1.62e+00, acc. prob=0.893]Sample:  94%|█████████▍| 9570/10200 [00:24, 395.16it/s, step size=1.62e+00, acc. prob=0.893]Sample:  94%|█████████▍| 9610/10200 [00:24, 396.55it/s, step size=1.62e+00, acc. prob=0.893]Sample:  95%|█████████▍| 9654/10200 [00:24, 405.64it/s, step size=1.62e+00, acc. prob=0.893]Sample:  95%|█████████▌| 9695/10200 [00:24, 405.82it/s, step size=1.62e+00, acc. prob=0.893]Sample:  95%|█████████▌| 9736/10200 [00:25, 399.80it/s, step size=1.62e+00, acc. prob=0.894]Sample:  96%|█████████▌| 9777/10200 [00:25, 400.96it/s, step size=1.62e+00, acc. prob=0.894]Sample:  96%|█████████▋| 9822/10200 [00:25, 412.91it/s, step size=1.62e+00, acc. prob=0.894]Sample:  97%|█████████▋| 9864/10200 [00:25, 397.47it/s, step size=1.62e+00, acc. prob=0.894]Sample:  97%|█████████▋| 9906/10200 [00:25, 403.80it/s, step size=1.62e+00, acc. prob=0.894]Sample:  98%|█████████▊| 9947/10200 [00:25, 404.02it/s, step size=1.62e+00, acc. prob=0.894]Sample:  98%|█████████▊| 9988/10200 [00:25, 398.77it/s, step size=1.62e+00, acc. prob=0.894]Sample:  98%|█████████▊| 10028/10200 [00:25, 395.45it/s, step size=1.62e+00, acc. prob=0.894]Sample:  99%|█████████▊| 10068/10200 [00:25, 391.07it/s, step size=1.62e+00, acc. prob=0.894]Sample:  99%|█████████▉| 10108/10200 [00:26, 385.07it/s, step size=1.62e+00, acc. prob=0.894]Sample:  99%|█████████▉| 10147/10200 [00:26, 384.27it/s, step size=1.62e+00, acc. prob=0.894]Sample: 100%|█████████▉| 10186/10200 [00:26, 384.22it/s, step size=1.62e+00, acc. prob=0.894]Sample: 100%|██████████| 10200/10200 [00:26, 388.54it/s, step size=1.62e+00, acc. prob=0.894]\n\n\n{'prob_thumb_up': tensor([0.2494, 0.4574, 0.4574,  ..., 0.4894, 0.7621, 0.7621])}\n\n\narray([[&lt;Axes: title={'center': 'prob_thumb_up'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\nThis distribution looks much more regular. From this, we can calculate the confidence interval for our restaurant’s “true rating”.\n\n# Compute confidence interval\nconfidence_interval = torch.quantile(prob_thumb_up_samples, torch.tensor([0.025, 0.975]))\n\nprint(f\"Estimated probability of thumb up: {prob_thumb_up_samples.mean().item():.4f}\")\nprint(f\"95% confidence interval: {confidence_interval.tolist()}\")\n\nEstimated probability of thumb up: 0.6661\n95% confidence interval: [0.15158675611019135, 0.9878186583518982]\n\n\nWe should also probably check to make sure that our estimates are valid. This particular example is trivial because of our choice of distribution and prior. Because we used a conjugate prior (Beta) for our observed data (Binomial/Bernoulli), we have a closed form solution for our expected result. I mentioned before that the a and b parameters for the Beta(a,b) distribution are pseudocounts for successes (thumbs up) and failures (thumbs down), respectively. That means that if our prior distribution has the form Beta(1,1) and we have observed 1 additional success, our posterior distribution has the form Beta(2,1).\nYou can see slide 12 of David Maracek’s excellent lecture on Beta-Bernoulli distributions to see what this looks like, or you can draw the Beta(2,1) distribution yourself using this applet.\nThe shape of our simulated posterior looks almost exactly like our expected output. Success!\nHow a content rating system wants to use this information would be up to them. In Reddit’s case, it looks like they used an 80% bound to rank their posts. If you want your ranking to be much stricter, you could use the lower bound of the credible interval, which would push new entries to the bottom of the ranking. You could also increase the number of pseudocounts in your Beta prior to something like the mean value of upvotes and downvotes, which may be more appropriate if you want new content to be ranked “average” until proven otherwise.\nIn some cases, it may be more appropriate to do this in a regression framework so that you can control for other variables. I’m going to repeat this analysis using logistic regression, which models the log-odds of a success. I’ll also do it on the GPU (although for small samples and simple models this may not be necessary due to the overhead incurred by moving data to your GPU).\nFirst we’ll check to see if we can use our GPU. If we can, we’ll create our data on our GPU. All of the data needs to be in one place for this to work and it will default to your CPU, so you’ll need to explicitly put everything on your GPU. A GPU will actually be a bit slower for this use case due to the overhead incurred, but it’s a good reference for larger models.\n\n# Check for CUDA availability and prepare data\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    # Create data tensor on GPU\n    data = torch.tensor([1.]).to(device)\n    print(\"Data moved to GPU.\")\nelse:\n    device = torch.device(\"cpu\")\n    data = torch.tensor([1.]).to(device)\n    print(\"CUDA not available, running on CPU.\")\n    \n# Validate devices\ntorch.cuda.get_device_name(torch.cuda.current_device())\n\nData moved to GPU.\n\n\n'NVIDIA GeForce RTX 3050 Laptop GPU'\n\n\nNext we’ll define our model. This model is going to look different from the previous one. In our logistic regression, the intercept will give us the log-odds of our restaurant’s true probability of thumbs up. This parameter is no longer bounded on [0,1], which means the Beta distribution is no longer appropriate. There are a few options here. * A normal distribution with mean 0 (p = 0.5 means the odds are (0.5) / (1 - 0.5) = 1, and log(1) = 0. This is a common choice, but choosing the variance is tricky because there is no closed form solution, so we would have to pick one based on how informative we want it to be. * A Cauchy distribution with mean 0 (for the same reason) and scale 2.5. This is based on the recommendation of Gelman et al (2008) (http://www.stat.columbia.edu/~gelman/research/published/priors11.pdf). There is still no way to properly estimate the variance of the intercept, so our choice is again going to affect our outcomes.\n\ndef logistic_model(data):  \n    # Create parameters for the distribution on the correct device\n    mean = torch.tensor(0., device=device)  # Ensure mean is a tensor on GPU\n    scale = torch.tensor(2.5, device=device)  # Ensure standard deviation is a tensor on GPU\n    \n    # Create the Cauchy distribution with parameters on the correct device\n    prior_dist = dist.Cauchy(mean, scale)\n    \n    # Sample intercept from the distribution\n    intercept = pyro.sample(\"intercept\", prior_dist)\n    \n    # Observing the data with Bernoulli likelihood\n    with pyro.plate(\"data_plate\", len(data)):\n        pyro.sample(\"obs\", dist.Bernoulli(logits=intercept), obs=data)\n\nThen we repeat our sampling. I repeated this a few times before settling on 2000 samples for decent convergence.\n\n#NUTS sampler\nnuts_kernel = NUTS(logistic_model)\nmcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=200)\nmcmc.run(data)\n\nWarmup:   0%|          | 0/2200 [00:00, ?it/s]Warmup:   0%|          | 1/2200 [00:00,  5.85it/s, step size=2.84e+01, acc. prob=0.993]Warmup:   0%|          | 9/2200 [00:00, 39.26it/s, step size=5.64e+00, acc. prob=0.755]Warmup:   1%|          | 14/2200 [00:00, 39.59it/s, step size=4.16e+00, acc. prob=0.764]Warmup:   1%|          | 19/2200 [00:00, 36.82it/s, step size=4.07e+00, acc. prob=0.772]Warmup:   1%|          | 27/2200 [00:00, 45.20it/s, step size=1.69e+00, acc. prob=0.767]Warmup:   1%|▏         | 32/2200 [00:00, 30.57it/s, step size=2.52e+00, acc. prob=0.776]Warmup:   2%|▏         | 40/2200 [00:01, 40.26it/s, step size=4.15e+00, acc. prob=0.784]Warmup:   2%|▏         | 53/2200 [00:01, 49.08it/s, step size=3.20e+00, acc. prob=0.785]Warmup:   3%|▎         | 59/2200 [00:01, 41.82it/s, step size=5.02e+00, acc. prob=0.789]Warmup:   3%|▎         | 67/2200 [00:01, 46.31it/s, step size=4.19e+00, acc. prob=0.789]Warmup:   4%|▎         | 77/2200 [00:01, 56.37it/s, step size=8.66e+00, acc. prob=0.795]Warmup:   4%|▍         | 85/2200 [00:01, 61.27it/s, step size=1.92e+01, acc. prob=0.800]Warmup:   4%|▍         | 92/2200 [00:01, 55.54it/s, step size=1.73e+00, acc. prob=0.786]Warmup:   5%|▍         | 102/2200 [00:02, 64.68it/s, step size=6.58e-02, acc. prob=0.778]Warmup:   5%|▌         | 110/2200 [00:02, 58.45it/s, step size=3.03e-01, acc. prob=0.786]Warmup:   5%|▌         | 119/2200 [00:02, 62.69it/s, step size=2.33e-01, acc. prob=0.786]Warmup:   6%|▌         | 127/2200 [00:02, 64.13it/s, step size=7.26e-02, acc. prob=0.783]Warmup:   6%|▌         | 135/2200 [00:02, 67.45it/s, step size=4.17e-02, acc. prob=0.782]Warmup:   6%|▋         | 143/2200 [00:02, 69.80it/s, step size=9.40e-02, acc. prob=0.785]Warmup:   7%|▋         | 151/2200 [00:02, 61.78it/s, step size=1.17e+00, acc. prob=0.774]Warmup:   7%|▋         | 159/2200 [00:02, 63.30it/s, step size=4.65e-01, acc. prob=0.776]Warmup:   8%|▊         | 170/2200 [00:03, 69.77it/s, step size=3.14e-01, acc. prob=0.776]Warmup:   8%|▊         | 179/2200 [00:03, 74.09it/s, step size=4.07e-01, acc. prob=0.777]Warmup:   8%|▊         | 187/2200 [00:03, 62.42it/s, step size=3.11e-01, acc. prob=0.777]Warmup:   9%|▉         | 201/2200 [00:03, 80.38it/s, step size=4.39e-01, acc. prob=1.000]Sample:  10%|▉         | 210/2200 [00:03, 77.26it/s, step size=4.39e-01, acc. prob=0.948]Sample:  10%|▉         | 219/2200 [00:03, 70.39it/s, step size=4.39e-01, acc. prob=0.952]Sample:  10%|█         | 231/2200 [00:03, 81.01it/s, step size=4.39e-01, acc. prob=0.953]Sample:  11%|█         | 240/2200 [00:04, 79.10it/s, step size=4.39e-01, acc. prob=0.946]Sample:  11%|█▏        | 249/2200 [00:04, 59.81it/s, step size=4.39e-01, acc. prob=0.942]Sample:  12%|█▏        | 256/2200 [00:04, 46.50it/s, step size=4.39e-01, acc. prob=0.946]Sample:  12%|█▏        | 262/2200 [00:04, 46.30it/s, step size=4.39e-01, acc. prob=0.945]Sample:  12%|█▏        | 272/2200 [00:04, 56.92it/s, step size=4.39e-01, acc. prob=0.943]Sample:  13%|█▎        | 281/2200 [00:04, 63.88it/s, step size=4.39e-01, acc. prob=0.949]Sample:  13%|█▎        | 291/2200 [00:04, 71.15it/s, step size=4.39e-01, acc. prob=0.950]Sample:  14%|█▎        | 301/2200 [00:05, 78.19it/s, step size=4.39e-01, acc. prob=0.949]Sample:  14%|█▍        | 310/2200 [00:05, 77.04it/s, step size=4.39e-01, acc. prob=0.949]Sample:  15%|█▍        | 321/2200 [00:05, 83.51it/s, step size=4.39e-01, acc. prob=0.953]Sample:  15%|█▌        | 330/2200 [00:05, 80.71it/s, step size=4.39e-01, acc. prob=0.947]Sample:  15%|█▌        | 339/2200 [00:05, 50.00it/s, step size=4.39e-01, acc. prob=0.950]Sample:  16%|█▌        | 346/2200 [00:05, 47.14it/s, step size=4.39e-01, acc. prob=0.949]Sample:  16%|█▌        | 355/2200 [00:06, 54.32it/s, step size=4.39e-01, acc. prob=0.946]Sample:  16%|█▋        | 362/2200 [00:06, 55.18it/s, step size=4.39e-01, acc. prob=0.944]Sample:  17%|█▋        | 369/2200 [00:06, 55.28it/s, step size=4.39e-01, acc. prob=0.943]Sample:  17%|█▋        | 376/2200 [00:06, 45.76it/s, step size=4.39e-01, acc. prob=0.941]Sample:  17%|█▋        | 382/2200 [00:06, 42.53it/s, step size=4.39e-01, acc. prob=0.942]Sample:  18%|█▊        | 387/2200 [00:06, 41.75it/s, step size=4.39e-01, acc. prob=0.943]Sample:  18%|█▊        | 395/2200 [00:06, 48.05it/s, step size=4.39e-01, acc. prob=0.945]Sample:  18%|█▊        | 401/2200 [00:07, 50.44it/s, step size=4.39e-01, acc. prob=0.945]Sample:  19%|█▊        | 409/2200 [00:07, 56.44it/s, step size=4.39e-01, acc. prob=0.946]Sample:  19%|█▉        | 418/2200 [00:07, 63.38it/s, step size=4.39e-01, acc. prob=0.946]Sample:  19%|█▉        | 425/2200 [00:07, 53.83it/s, step size=4.39e-01, acc. prob=0.945]Sample:  20%|█▉        | 432/2200 [00:07, 44.45it/s, step size=4.39e-01, acc. prob=0.945]Sample:  20%|█▉        | 437/2200 [00:07, 35.65it/s, step size=4.39e-01, acc. prob=0.944]Sample:  20%|██        | 446/2200 [00:08, 45.50it/s, step size=4.39e-01, acc. prob=0.945]Sample:  21%|██        | 454/2200 [00:08, 51.66it/s, step size=4.39e-01, acc. prob=0.945]Sample:  21%|██        | 462/2200 [00:08, 56.94it/s, step size=4.39e-01, acc. prob=0.946]Sample:  21%|██▏       | 469/2200 [00:08, 55.64it/s, step size=4.39e-01, acc. prob=0.946]Sample:  22%|██▏       | 476/2200 [00:08, 55.36it/s, step size=4.39e-01, acc. prob=0.947]Sample:  22%|██▏       | 482/2200 [00:08, 56.15it/s, step size=4.39e-01, acc. prob=0.947]Sample:  22%|██▏       | 490/2200 [00:08, 60.88it/s, step size=4.39e-01, acc. prob=0.947]Sample:  23%|██▎       | 497/2200 [00:09, 41.18it/s, step size=4.39e-01, acc. prob=0.948]Sample:  23%|██▎       | 503/2200 [00:09, 42.70it/s, step size=4.39e-01, acc. prob=0.948]Sample:  23%|██▎       | 512/2200 [00:09, 52.04it/s, step size=4.39e-01, acc. prob=0.948]Sample:  24%|██▎       | 519/2200 [00:09, 47.54it/s, step size=4.39e-01, acc. prob=0.948]Sample:  24%|██▍       | 529/2200 [00:09, 58.19it/s, step size=4.39e-01, acc. prob=0.947]Sample:  24%|██▍       | 537/2200 [00:09, 58.56it/s, step size=4.39e-01, acc. prob=0.947]Sample:  25%|██▍       | 544/2200 [00:09, 51.41it/s, step size=4.39e-01, acc. prob=0.948]Sample:  25%|██▌       | 550/2200 [00:09, 51.93it/s, step size=4.39e-01, acc. prob=0.948]Sample:  25%|██▌       | 556/2200 [00:10, 52.71it/s, step size=4.39e-01, acc. prob=0.949]Sample:  26%|██▌       | 563/2200 [00:10, 55.48it/s, step size=4.39e-01, acc. prob=0.947]Sample:  26%|██▌       | 569/2200 [00:10, 49.20it/s, step size=4.39e-01, acc. prob=0.945]Sample:  26%|██▌       | 575/2200 [00:10, 45.69it/s, step size=4.39e-01, acc. prob=0.946]Sample:  27%|██▋       | 587/2200 [00:10, 61.82it/s, step size=4.39e-01, acc. prob=0.945]Sample:  27%|██▋       | 597/2200 [00:10, 68.72it/s, step size=4.39e-01, acc. prob=0.944]Sample:  28%|██▊       | 606/2200 [00:10, 71.22it/s, step size=4.39e-01, acc. prob=0.944]Sample:  28%|██▊       | 614/2200 [00:10, 65.69it/s, step size=4.39e-01, acc. prob=0.945]Sample:  28%|██▊       | 624/2200 [00:11, 72.58it/s, step size=4.39e-01, acc. prob=0.943]Sample:  29%|██▊       | 632/2200 [00:11, 71.36it/s, step size=4.39e-01, acc. prob=0.943]Sample:  29%|██▉       | 640/2200 [00:11, 60.66it/s, step size=4.39e-01, acc. prob=0.943]Sample:  29%|██▉       | 648/2200 [00:11, 64.90it/s, step size=4.39e-01, acc. prob=0.944]Sample:  30%|██▉       | 657/2200 [00:11, 70.73it/s, step size=4.39e-01, acc. prob=0.944]Sample:  30%|███       | 666/2200 [00:11, 75.39it/s, step size=4.39e-01, acc. prob=0.944]Sample:  31%|███       | 674/2200 [00:11, 71.77it/s, step size=4.39e-01, acc. prob=0.944]Sample:  31%|███       | 682/2200 [00:11, 72.61it/s, step size=4.39e-01, acc. prob=0.944]Sample:  31%|███▏      | 690/2200 [00:12, 74.62it/s, step size=4.39e-01, acc. prob=0.944]Sample:  32%|███▏      | 698/2200 [00:12, 74.05it/s, step size=4.39e-01, acc. prob=0.944]Sample:  32%|███▏      | 706/2200 [00:12, 54.84it/s, step size=4.39e-01, acc. prob=0.944]Sample:  32%|███▏      | 713/2200 [00:12, 55.15it/s, step size=4.39e-01, acc. prob=0.943]Sample:  33%|███▎      | 720/2200 [00:12, 52.98it/s, step size=4.39e-01, acc. prob=0.943]Sample:  33%|███▎      | 726/2200 [00:12, 49.36it/s, step size=4.39e-01, acc. prob=0.944]Sample:  33%|███▎      | 732/2200 [00:13, 37.30it/s, step size=4.39e-01, acc. prob=0.944]Sample:  34%|███▎      | 737/2200 [00:13, 37.19it/s, step size=4.39e-01, acc. prob=0.944]Sample:  34%|███▎      | 742/2200 [00:13, 33.80it/s, step size=4.39e-01, acc. prob=0.944]Sample:  34%|███▍      | 746/2200 [00:13, 31.58it/s, step size=4.39e-01, acc. prob=0.945]Sample:  34%|███▍      | 755/2200 [00:13, 43.32it/s, step size=4.39e-01, acc. prob=0.945]Sample:  35%|███▍      | 763/2200 [00:13, 50.55it/s, step size=4.39e-01, acc. prob=0.945]Sample:  35%|███▌      | 771/2200 [00:13, 57.19it/s, step size=4.39e-01, acc. prob=0.945]Sample:  35%|███▌      | 778/2200 [00:13, 54.12it/s, step size=4.39e-01, acc. prob=0.945]Sample:  36%|███▌      | 784/2200 [00:14, 33.10it/s, step size=4.39e-01, acc. prob=0.946]Sample:  36%|███▌      | 789/2200 [00:14, 27.62it/s, step size=4.39e-01, acc. prob=0.945]Sample:  36%|███▌      | 796/2200 [00:14, 34.25it/s, step size=4.39e-01, acc. prob=0.946]Sample:  37%|███▋      | 807/2200 [00:14, 47.44it/s, step size=4.39e-01, acc. prob=0.945]Sample:  37%|███▋      | 818/2200 [00:14, 59.66it/s, step size=4.39e-01, acc. prob=0.944]Sample:  38%|███▊      | 826/2200 [00:15, 59.92it/s, step size=4.39e-01, acc. prob=0.944]Sample:  38%|███▊      | 834/2200 [00:15, 57.86it/s, step size=4.39e-01, acc. prob=0.943]Sample:  38%|███▊      | 841/2200 [00:15, 56.15it/s, step size=4.39e-01, acc. prob=0.942]Sample:  39%|███▊      | 848/2200 [00:15, 58.88it/s, step size=4.39e-01, acc. prob=0.942]Sample:  39%|███▉      | 858/2200 [00:15, 66.65it/s, step size=4.39e-01, acc. prob=0.942]Sample:  39%|███▉      | 866/2200 [00:15, 69.34it/s, step size=4.39e-01, acc. prob=0.942]Sample:  40%|███▉      | 876/2200 [00:15, 77.04it/s, step size=4.39e-01, acc. prob=0.943]Sample:  40%|████      | 885/2200 [00:15, 75.82it/s, step size=4.39e-01, acc. prob=0.942]Sample:  41%|████      | 893/2200 [00:16, 64.33it/s, step size=4.39e-01, acc. prob=0.942]Sample:  41%|████      | 903/2200 [00:16, 70.45it/s, step size=4.39e-01, acc. prob=0.941]Sample:  41%|████▏     | 911/2200 [00:16, 69.53it/s, step size=4.39e-01, acc. prob=0.942]Sample:  42%|████▏     | 919/2200 [00:16, 71.11it/s, step size=4.39e-01, acc. prob=0.942]Sample:  42%|████▏     | 927/2200 [00:16, 68.96it/s, step size=4.39e-01, acc. prob=0.942]Sample:  42%|████▎     | 935/2200 [00:16, 67.00it/s, step size=4.39e-01, acc. prob=0.942]Sample:  43%|████▎     | 942/2200 [00:16, 54.34it/s, step size=4.39e-01, acc. prob=0.942]Sample:  43%|████▎     | 953/2200 [00:16, 66.44it/s, step size=4.39e-01, acc. prob=0.942]Sample:  44%|████▎     | 961/2200 [00:17, 66.97it/s, step size=4.39e-01, acc. prob=0.942]Sample:  44%|████▍     | 969/2200 [00:17, 66.57it/s, step size=4.39e-01, acc. prob=0.942]Sample:  44%|████▍     | 978/2200 [00:17, 71.07it/s, step size=4.39e-01, acc. prob=0.941]Sample:  45%|████▍     | 986/2200 [00:17, 58.90it/s, step size=4.39e-01, acc. prob=0.941]Sample:  45%|████▌     | 993/2200 [00:17, 57.41it/s, step size=4.39e-01, acc. prob=0.941]Sample:  45%|████▌     | 1000/2200 [00:17, 58.18it/s, step size=4.39e-01, acc. prob=0.941]Sample:  46%|████▌     | 1007/2200 [00:17, 57.10it/s, step size=4.39e-01, acc. prob=0.941]Sample:  46%|████▌     | 1014/2200 [00:18, 58.92it/s, step size=4.39e-01, acc. prob=0.941]Sample:  47%|████▋     | 1024/2200 [00:18, 67.87it/s, step size=4.39e-01, acc. prob=0.941]Sample:  47%|████▋     | 1032/2200 [00:18, 66.51it/s, step size=4.39e-01, acc. prob=0.941]Sample:  47%|████▋     | 1041/2200 [00:18, 68.86it/s, step size=4.39e-01, acc. prob=0.941]Sample:  48%|████▊     | 1048/2200 [00:18, 68.98it/s, step size=4.39e-01, acc. prob=0.942]Sample:  48%|████▊     | 1055/2200 [00:18, 65.10it/s, step size=4.39e-01, acc. prob=0.941]Sample:  48%|████▊     | 1062/2200 [00:18, 53.10it/s, step size=4.39e-01, acc. prob=0.942]Sample:  49%|████▊     | 1068/2200 [00:19, 43.09it/s, step size=4.39e-01, acc. prob=0.942]Sample:  49%|████▉     | 1077/2200 [00:19, 52.75it/s, step size=4.39e-01, acc. prob=0.942]Sample:  49%|████▉     | 1085/2200 [00:19, 58.58it/s, step size=4.39e-01, acc. prob=0.942]Sample:  50%|████▉     | 1092/2200 [00:19, 53.51it/s, step size=4.39e-01, acc. prob=0.941]Sample:  50%|████▉     | 1098/2200 [00:19, 54.27it/s, step size=4.39e-01, acc. prob=0.941]Sample:  50%|█████     | 1105/2200 [00:19, 57.14it/s, step size=4.39e-01, acc. prob=0.941]Sample:  51%|█████     | 1113/2200 [00:19, 62.72it/s, step size=4.39e-01, acc. prob=0.941]Sample:  51%|█████     | 1120/2200 [00:19, 51.76it/s, step size=4.39e-01, acc. prob=0.940]Sample:  51%|█████     | 1126/2200 [00:20, 29.82it/s, step size=4.39e-01, acc. prob=0.941]Sample:  51%|█████▏    | 1131/2200 [00:21, 16.46it/s, step size=4.39e-01, acc. prob=0.941]Sample:  52%|█████▏    | 1135/2200 [00:21, 16.83it/s, step size=4.39e-01, acc. prob=0.941]Sample:  52%|█████▏    | 1139/2200 [00:21, 18.87it/s, step size=4.39e-01, acc. prob=0.941]Sample:  52%|█████▏    | 1145/2200 [00:21, 24.21it/s, step size=4.39e-01, acc. prob=0.941]Sample:  52%|█████▏    | 1150/2200 [00:21, 28.07it/s, step size=4.39e-01, acc. prob=0.941]Sample:  52%|█████▎    | 1155/2200 [00:21, 32.03it/s, step size=4.39e-01, acc. prob=0.942]Sample:  53%|█████▎    | 1160/2200 [00:21, 34.84it/s, step size=4.39e-01, acc. prob=0.942]Sample:  53%|█████▎    | 1167/2200 [00:21, 39.58it/s, step size=4.39e-01, acc. prob=0.942]Sample:  54%|█████▎    | 1178/2200 [00:22, 55.24it/s, step size=4.39e-01, acc. prob=0.942]Sample:  54%|█████▍    | 1185/2200 [00:22, 57.04it/s, step size=4.39e-01, acc. prob=0.942]Sample:  54%|█████▍    | 1192/2200 [00:22, 51.79it/s, step size=4.39e-01, acc. prob=0.942]Sample:  54%|█████▍    | 1198/2200 [00:22, 44.64it/s, step size=4.39e-01, acc. prob=0.942]Sample:  55%|█████▍    | 1203/2200 [00:22, 44.88it/s, step size=4.39e-01, acc. prob=0.942]Sample:  55%|█████▍    | 1208/2200 [00:22, 41.06it/s, step size=4.39e-01, acc. prob=0.943]Sample:  55%|█████▌    | 1216/2200 [00:22, 49.24it/s, step size=4.39e-01, acc. prob=0.943]Sample:  56%|█████▌    | 1223/2200 [00:23, 53.27it/s, step size=4.39e-01, acc. prob=0.943]Sample:  56%|█████▌    | 1235/2200 [00:23, 68.55it/s, step size=4.39e-01, acc. prob=0.942]Sample:  56%|█████▋    | 1243/2200 [00:23, 68.20it/s, step size=4.39e-01, acc. prob=0.942]Sample:  57%|█████▋    | 1251/2200 [00:23, 67.54it/s, step size=4.39e-01, acc. prob=0.943]Sample:  57%|█████▋    | 1259/2200 [00:23, 70.81it/s, step size=4.39e-01, acc. prob=0.942]Sample:  58%|█████▊    | 1267/2200 [00:23, 67.34it/s, step size=4.39e-01, acc. prob=0.942]Sample:  58%|█████▊    | 1274/2200 [00:23, 59.29it/s, step size=4.39e-01, acc. prob=0.943]Sample:  58%|█████▊    | 1281/2200 [00:23, 53.48it/s, step size=4.39e-01, acc. prob=0.943]Sample:  59%|█████▊    | 1292/2200 [00:24, 63.28it/s, step size=4.39e-01, acc. prob=0.943]Sample:  59%|█████▉    | 1299/2200 [00:24, 64.77it/s, step size=4.39e-01, acc. prob=0.943]Sample:  59%|█████▉    | 1308/2200 [00:24, 70.15it/s, step size=4.39e-01, acc. prob=0.944]Sample:  60%|█████▉    | 1317/2200 [00:24, 73.27it/s, step size=4.39e-01, acc. prob=0.944]Sample:  60%|██████    | 1326/2200 [00:24, 75.94it/s, step size=4.39e-01, acc. prob=0.944]Sample:  61%|██████    | 1335/2200 [00:24, 78.71it/s, step size=4.39e-01, acc. prob=0.944]Sample:  61%|██████    | 1345/2200 [00:24, 78.11it/s, step size=4.39e-01, acc. prob=0.944]Sample:  62%|██████▏   | 1353/2200 [00:24, 68.84it/s, step size=4.39e-01, acc. prob=0.944]Sample:  62%|██████▏   | 1361/2200 [00:24, 66.47it/s, step size=4.39e-01, acc. prob=0.943]Sample:  62%|██████▏   | 1369/2200 [00:25, 68.83it/s, step size=4.39e-01, acc. prob=0.943]Sample:  63%|██████▎   | 1380/2200 [00:25, 75.04it/s, step size=4.39e-01, acc. prob=0.944]Sample:  63%|██████▎   | 1388/2200 [00:25, 63.21it/s, step size=4.39e-01, acc. prob=0.943]Sample:  63%|██████▎   | 1395/2200 [00:25, 56.04it/s, step size=4.39e-01, acc. prob=0.943]Sample:  64%|██████▎   | 1402/2200 [00:25, 58.08it/s, step size=4.39e-01, acc. prob=0.944]Sample:  64%|██████▍   | 1410/2200 [00:25, 63.34it/s, step size=4.39e-01, acc. prob=0.943]Sample:  64%|██████▍   | 1417/2200 [00:25, 63.26it/s, step size=4.39e-01, acc. prob=0.943]Sample:  65%|██████▍   | 1424/2200 [00:26, 55.32it/s, step size=4.39e-01, acc. prob=0.943]Sample:  65%|██████▌   | 1433/2200 [00:26, 62.48it/s, step size=4.39e-01, acc. prob=0.943]Sample:  66%|██████▌   | 1442/2200 [00:26, 65.94it/s, step size=4.39e-01, acc. prob=0.943]Sample:  66%|██████▌   | 1451/2200 [00:26, 72.08it/s, step size=4.39e-01, acc. prob=0.943]Sample:  66%|██████▋   | 1460/2200 [00:26, 75.90it/s, step size=4.39e-01, acc. prob=0.943]Sample:  67%|██████▋   | 1469/2200 [00:26, 76.91it/s, step size=4.39e-01, acc. prob=0.943]Sample:  67%|██████▋   | 1477/2200 [00:26, 65.48it/s, step size=4.39e-01, acc. prob=0.943]Sample:  68%|██████▊   | 1487/2200 [00:26, 71.89it/s, step size=4.39e-01, acc. prob=0.943]Sample:  68%|██████▊   | 1495/2200 [00:26, 72.49it/s, step size=4.39e-01, acc. prob=0.943]Sample:  68%|██████▊   | 1503/2200 [00:27, 61.10it/s, step size=4.39e-01, acc. prob=0.943]Sample:  69%|██████▊   | 1510/2200 [00:27, 53.16it/s, step size=4.39e-01, acc. prob=0.943]Sample:  69%|██████▉   | 1522/2200 [00:27, 66.61it/s, step size=4.39e-01, acc. prob=0.943]Sample:  70%|██████▉   | 1530/2200 [00:27, 64.08it/s, step size=4.39e-01, acc. prob=0.943]Sample:  70%|██████▉   | 1539/2200 [00:27, 65.56it/s, step size=4.39e-01, acc. prob=0.943]Sample:  70%|███████   | 1547/2200 [00:27, 68.53it/s, step size=4.39e-01, acc. prob=0.944]Sample:  71%|███████   | 1555/2200 [00:27, 69.16it/s, step size=4.39e-01, acc. prob=0.944]Sample:  71%|███████   | 1563/2200 [00:28, 70.88it/s, step size=4.39e-01, acc. prob=0.944]Sample:  71%|███████▏  | 1572/2200 [00:28, 73.94it/s, step size=4.39e-01, acc. prob=0.944]Sample:  72%|███████▏  | 1581/2200 [00:28, 77.88it/s, step size=4.39e-01, acc. prob=0.944]Sample:  72%|███████▏  | 1589/2200 [00:28, 71.84it/s, step size=4.39e-01, acc. prob=0.944]Sample:  73%|███████▎  | 1600/2200 [00:28, 80.10it/s, step size=4.39e-01, acc. prob=0.944]Sample:  73%|███████▎  | 1609/2200 [00:28, 78.47it/s, step size=4.39e-01, acc. prob=0.944]Sample:  74%|███████▎  | 1617/2200 [00:28, 76.22it/s, step size=4.39e-01, acc. prob=0.944]Sample:  74%|███████▍  | 1625/2200 [00:28, 75.01it/s, step size=4.39e-01, acc. prob=0.945]Sample:  74%|███████▍  | 1634/2200 [00:28, 78.67it/s, step size=4.39e-01, acc. prob=0.945]Sample:  75%|███████▍  | 1642/2200 [00:29, 76.88it/s, step size=4.39e-01, acc. prob=0.945]Sample:  75%|███████▌  | 1650/2200 [00:29, 77.12it/s, step size=4.39e-01, acc. prob=0.945]Sample:  75%|███████▌  | 1658/2200 [00:29, 69.27it/s, step size=4.39e-01, acc. prob=0.945]Sample:  76%|███████▌  | 1666/2200 [00:29, 67.47it/s, step size=4.39e-01, acc. prob=0.945]Sample:  76%|███████▌  | 1675/2200 [00:29, 72.04it/s, step size=4.39e-01, acc. prob=0.945]Sample:  77%|███████▋  | 1684/2200 [00:29, 75.28it/s, step size=4.39e-01, acc. prob=0.945]Sample:  77%|███████▋  | 1693/2200 [00:29, 77.62it/s, step size=4.39e-01, acc. prob=0.945]Sample:  77%|███████▋  | 1701/2200 [00:29, 76.59it/s, step size=4.39e-01, acc. prob=0.945]Sample:  78%|███████▊  | 1712/2200 [00:29, 82.77it/s, step size=4.39e-01, acc. prob=0.945]Sample:  78%|███████▊  | 1721/2200 [00:30, 64.86it/s, step size=4.39e-01, acc. prob=0.945]Sample:  79%|███████▊  | 1729/2200 [00:30, 62.83it/s, step size=4.39e-01, acc. prob=0.945]Sample:  79%|███████▉  | 1738/2200 [00:30, 69.02it/s, step size=4.39e-01, acc. prob=0.945]Sample:  79%|███████▉  | 1746/2200 [00:30, 68.68it/s, step size=4.39e-01, acc. prob=0.945]Sample:  80%|███████▉  | 1754/2200 [00:30, 58.15it/s, step size=4.39e-01, acc. prob=0.945]Sample:  80%|████████  | 1762/2200 [00:30, 62.57it/s, step size=4.39e-01, acc. prob=0.945]Sample:  81%|████████  | 1772/2200 [00:30, 68.82it/s, step size=4.39e-01, acc. prob=0.945]Sample:  81%|████████  | 1785/2200 [00:31, 83.75it/s, step size=4.39e-01, acc. prob=0.945]Sample:  82%|████████▏ | 1795/2200 [00:31, 86.65it/s, step size=4.39e-01, acc. prob=0.945]Sample:  82%|████████▏ | 1805/2200 [00:31, 81.08it/s, step size=4.39e-01, acc. prob=0.944]Sample:  82%|████████▏ | 1814/2200 [00:31, 60.84it/s, step size=4.39e-01, acc. prob=0.944]Sample:  83%|████████▎ | 1822/2200 [00:31, 50.35it/s, step size=4.39e-01, acc. prob=0.944]Sample:  83%|████████▎ | 1828/2200 [00:31, 46.00it/s, step size=4.39e-01, acc. prob=0.944]Sample:  84%|████████▎ | 1837/2200 [00:32, 51.24it/s, step size=4.39e-01, acc. prob=0.944]Sample:  84%|████████▍ | 1845/2200 [00:32, 52.91it/s, step size=4.39e-01, acc. prob=0.944]Sample:  84%|████████▍ | 1851/2200 [00:32, 53.18it/s, step size=4.39e-01, acc. prob=0.944]Sample:  84%|████████▍ | 1857/2200 [00:32, 51.32it/s, step size=4.39e-01, acc. prob=0.944]Sample:  85%|████████▍ | 1863/2200 [00:32, 48.61it/s, step size=4.39e-01, acc. prob=0.944]Sample:  85%|████████▍ | 1868/2200 [00:32, 46.64it/s, step size=4.39e-01, acc. prob=0.944]Sample:  85%|████████▌ | 1876/2200 [00:32, 54.58it/s, step size=4.39e-01, acc. prob=0.944]Sample:  86%|████████▌ | 1883/2200 [00:32, 56.37it/s, step size=4.39e-01, acc. prob=0.944]Sample:  86%|████████▌ | 1892/2200 [00:33, 64.47it/s, step size=4.39e-01, acc. prob=0.944]Sample:  86%|████████▋ | 1900/2200 [00:33, 68.47it/s, step size=4.39e-01, acc. prob=0.944]Sample:  87%|████████▋ | 1908/2200 [00:33, 66.37it/s, step size=4.39e-01, acc. prob=0.944]Sample:  87%|████████▋ | 1916/2200 [00:33, 68.70it/s, step size=4.39e-01, acc. prob=0.944]Sample:  87%|████████▋ | 1923/2200 [00:33, 62.01it/s, step size=4.39e-01, acc. prob=0.944]Sample:  88%|████████▊ | 1930/2200 [00:33, 59.96it/s, step size=4.39e-01, acc. prob=0.944]Sample:  88%|████████▊ | 1937/2200 [00:33, 57.76it/s, step size=4.39e-01, acc. prob=0.944]Sample:  88%|████████▊ | 1943/2200 [00:33, 55.92it/s, step size=4.39e-01, acc. prob=0.944]Sample:  89%|████████▊ | 1950/2200 [00:34, 56.63it/s, step size=4.39e-01, acc. prob=0.944]Sample:  89%|████████▉ | 1957/2200 [00:34, 59.18it/s, step size=4.39e-01, acc. prob=0.944]Sample:  89%|████████▉ | 1964/2200 [00:34, 58.72it/s, step size=4.39e-01, acc. prob=0.944]Sample:  90%|████████▉ | 1973/2200 [00:34, 66.49it/s, step size=4.39e-01, acc. prob=0.945]Sample:  90%|█████████ | 1985/2200 [00:34, 78.13it/s, step size=4.39e-01, acc. prob=0.944]Sample:  91%|█████████ | 1993/2200 [00:34, 68.62it/s, step size=4.39e-01, acc. prob=0.944]Sample:  91%|█████████ | 2001/2200 [00:34, 46.55it/s, step size=4.39e-01, acc. prob=0.944]Sample:  91%|█████████ | 2007/2200 [00:35, 46.88it/s, step size=4.39e-01, acc. prob=0.945]Sample:  92%|█████████▏| 2014/2200 [00:35, 47.18it/s, step size=4.39e-01, acc. prob=0.945]Sample:  92%|█████████▏| 2020/2200 [00:35, 45.28it/s, step size=4.39e-01, acc. prob=0.945]Sample:  92%|█████████▏| 2028/2200 [00:35, 51.77it/s, step size=4.39e-01, acc. prob=0.944]Sample:  93%|█████████▎| 2038/2200 [00:35, 62.83it/s, step size=4.39e-01, acc. prob=0.945]Sample:  93%|█████████▎| 2047/2200 [00:35, 69.15it/s, step size=4.39e-01, acc. prob=0.945]Sample:  93%|█████████▎| 2055/2200 [00:35, 67.08it/s, step size=4.39e-01, acc. prob=0.945]Sample:  94%|█████████▍| 2063/2200 [00:35, 65.83it/s, step size=4.39e-01, acc. prob=0.945]Sample:  94%|█████████▍| 2071/2200 [00:36, 68.58it/s, step size=4.39e-01, acc. prob=0.945]Sample:  94%|█████████▍| 2079/2200 [00:36, 69.40it/s, step size=4.39e-01, acc. prob=0.945]Sample:  95%|█████████▍| 2087/2200 [00:36, 67.87it/s, step size=4.39e-01, acc. prob=0.945]Sample:  95%|█████████▌| 2094/2200 [00:36, 64.18it/s, step size=4.39e-01, acc. prob=0.945]Sample:  96%|█████████▌| 2101/2200 [00:36, 64.33it/s, step size=4.39e-01, acc. prob=0.945]Sample:  96%|█████████▌| 2108/2200 [00:36, 63.71it/s, step size=4.39e-01, acc. prob=0.945]Sample:  96%|█████████▌| 2115/2200 [00:36, 59.46it/s, step size=4.39e-01, acc. prob=0.945]Sample:  96%|█████████▋| 2122/2200 [00:36, 54.91it/s, step size=4.39e-01, acc. prob=0.945]Sample:  97%|█████████▋| 2130/2200 [00:36, 60.95it/s, step size=4.39e-01, acc. prob=0.946]Sample:  97%|█████████▋| 2137/2200 [00:37, 61.55it/s, step size=4.39e-01, acc. prob=0.946]Sample:  97%|█████████▋| 2144/2200 [00:37, 55.15it/s, step size=4.39e-01, acc. prob=0.946]Sample:  98%|█████████▊| 2150/2200 [00:37, 51.98it/s, step size=4.39e-01, acc. prob=0.946]Sample:  98%|█████████▊| 2161/2200 [00:37, 65.42it/s, step size=4.39e-01, acc. prob=0.946]Sample:  99%|█████████▊| 2168/2200 [00:37, 53.79it/s, step size=4.39e-01, acc. prob=0.946]Sample:  99%|█████████▉| 2176/2200 [00:37, 59.38it/s, step size=4.39e-01, acc. prob=0.946]Sample:  99%|█████████▉| 2186/2200 [00:37, 68.50it/s, step size=4.39e-01, acc. prob=0.946]Sample: 100%|█████████▉| 2194/2200 [00:38, 58.85it/s, step size=4.39e-01, acc. prob=0.946]Sample: 100%|██████████| 2200/2200 [00:38, 57.65it/s, step size=4.39e-01, acc. prob=0.946]\n\n\nAnd again check our model convergence. To plot these, we’ll also need to transfer these back to our CPU. We expect a normal distribution for the intercept parameter if the model converged. There are better ways to check the convergence such as Effective Sample Size (ESS) or Gelman-Rubin convergence, but they require running multiple chains which is finnicky on Windows.\n\n# Check model convergence\nintercept_df = pd.DataFrame({'intercept' : mcmc.get_samples()['intercept'].to('cpu')})\nintercept_df.hist()\n\narray([[&lt;Axes: title={'center': 'intercept'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\nThat doesn’t look very normal! Probably because we only have one sample. It’s possible that a distribution with smaller tails, like the normal, will work better here. Let’s try again with the normal distribution.\n\ndef logistic_model(data):  \n    # Create parameters for the distribution on the correct device\n    mean = torch.tensor(0., device=device)  # Ensure mean is a tensor on GPU\n    scale = torch.tensor(2.5, device=device)  # Ensure standard deviation is a tensor on GPU\n    \n    # Create the Normal distribution with parameters on the correct device\n    prior_dist = dist.Normal(mean, scale)\n    \n    # Sample intercept from the distribution\n    intercept = pyro.sample(\"intercept\", prior_dist)\n    \n    # Observing the data with Bernoulli likelihood\n    with pyro.plate(\"data_plate\", len(data)):\n        pyro.sample(\"obs\", dist.Bernoulli(logits=intercept), obs=data)\n\n\n#NUTS sampler\nnuts_kernel = NUTS(logistic_model)\nmcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=200)\nmcmc.run(data)\n\nWarmup:   0%|          | 0/2200 [00:00, ?it/s]Warmup:   0%|          | 9/2200 [00:00, 76.19it/s, step size=2.56e+00, acc. prob=0.703]Warmup:   1%|          | 18/2200 [00:00, 79.19it/s, step size=2.06e+00, acc. prob=0.746]Warmup:   1%|          | 26/2200 [00:00, 78.87it/s, step size=4.48e-01, acc. prob=0.739]Warmup:   2%|▏         | 34/2200 [00:00, 68.26it/s, step size=2.94e+00, acc. prob=0.771]Warmup:   2%|▏         | 47/2200 [00:00, 83.55it/s, step size=8.53e-01, acc. prob=0.766]Warmup:   3%|▎         | 63/2200 [00:00, 105.58it/s, step size=5.31e+00, acc. prob=0.785]Warmup:   4%|▎         | 82/2200 [00:00, 130.01it/s, step size=1.48e+00, acc. prob=0.780]Warmup:   4%|▍         | 96/2200 [00:00, 126.58it/s, step size=4.48e+00, acc. prob=0.788]Warmup:   5%|▍         | 109/2200 [00:01, 106.03it/s, step size=1.79e+00, acc. prob=0.776]Warmup:   6%|▌         | 121/2200 [00:01, 104.75it/s, step size=2.01e-01, acc. prob=0.771]Warmup:   6%|▌         | 132/2200 [00:01, 97.08it/s, step size=3.17e+00, acc. prob=0.780] Warmup:   7%|▋         | 147/2200 [00:01, 109.33it/s, step size=1.41e+00, acc. prob=0.779]Warmup:   7%|▋         | 159/2200 [00:01, 111.26it/s, step size=2.33e+00, acc. prob=0.773]Warmup:   8%|▊         | 171/2200 [00:01, 101.01it/s, step size=4.57e-01, acc. prob=0.772]Warmup:   8%|▊         | 182/2200 [00:01, 91.58it/s, step size=9.20e-01, acc. prob=0.774] Warmup:   9%|▉         | 195/2200 [00:01, 100.74it/s, step size=5.34e+00, acc. prob=0.779]Sample:   9%|▉         | 206/2200 [00:02, 100.79it/s, step size=1.23e+00, acc. prob=0.838]Sample:  10%|▉         | 217/2200 [00:02, 97.41it/s, step size=1.23e+00, acc. prob=0.871] Sample:  10%|█         | 231/2200 [00:02, 106.95it/s, step size=1.23e+00, acc. prob=0.898]Sample:  11%|█         | 243/2200 [00:02, 108.94it/s, step size=1.23e+00, acc. prob=0.875]Sample:  12%|█▏        | 255/2200 [00:02, 111.10it/s, step size=1.23e+00, acc. prob=0.878]Sample:  12%|█▏        | 267/2200 [00:02, 106.99it/s, step size=1.23e+00, acc. prob=0.876]Sample:  13%|█▎        | 278/2200 [00:02, 107.22it/s, step size=1.23e+00, acc. prob=0.861]Sample:  13%|█▎        | 293/2200 [00:02, 118.56it/s, step size=1.23e+00, acc. prob=0.878]Sample:  14%|█▍        | 306/2200 [00:02, 121.13it/s, step size=1.23e+00, acc. prob=0.882]Sample:  14%|█▍        | 319/2200 [00:03, 117.59it/s, step size=1.23e+00, acc. prob=0.881]Sample:  15%|█▌        | 333/2200 [00:03, 123.54it/s, step size=1.23e+00, acc. prob=0.887]Sample:  16%|█▌        | 346/2200 [00:03, 119.40it/s, step size=1.23e+00, acc. prob=0.886]Sample:  16%|█▋        | 359/2200 [00:03, 111.44it/s, step size=1.23e+00, acc. prob=0.883]Sample:  17%|█▋        | 371/2200 [00:03, 104.77it/s, step size=1.23e+00, acc. prob=0.883]Sample:  17%|█▋        | 382/2200 [00:03, 105.04it/s, step size=1.23e+00, acc. prob=0.883]Sample:  18%|█▊        | 393/2200 [00:03, 104.13it/s, step size=1.23e+00, acc. prob=0.883]Sample:  18%|█▊        | 404/2200 [00:03, 101.04it/s, step size=1.23e+00, acc. prob=0.887]Sample:  19%|█▉        | 416/2200 [00:03, 105.62it/s, step size=1.23e+00, acc. prob=0.886]Sample:  19%|█▉        | 427/2200 [00:04, 104.79it/s, step size=1.23e+00, acc. prob=0.889]Sample:  20%|█▉        | 438/2200 [00:04, 103.49it/s, step size=1.23e+00, acc. prob=0.891]Sample:  20%|██        | 449/2200 [00:04, 99.19it/s, step size=1.23e+00, acc. prob=0.891] Sample:  21%|██        | 461/2200 [00:04, 102.37it/s, step size=1.23e+00, acc. prob=0.894]Sample:  21%|██▏       | 472/2200 [00:04, 97.22it/s, step size=1.23e+00, acc. prob=0.892] Sample:  22%|██▏       | 486/2200 [00:04, 107.85it/s, step size=1.23e+00, acc. prob=0.895]Sample:  23%|██▎       | 499/2200 [00:04, 113.65it/s, step size=1.23e+00, acc. prob=0.898]Sample:  23%|██▎       | 511/2200 [00:04, 105.33it/s, step size=1.23e+00, acc. prob=0.899]Sample:  24%|██▎       | 522/2200 [00:04, 105.74it/s, step size=1.23e+00, acc. prob=0.900]Sample:  24%|██▍       | 533/2200 [00:05, 105.46it/s, step size=1.23e+00, acc. prob=0.901]Sample:  25%|██▍       | 548/2200 [00:05, 115.18it/s, step size=1.23e+00, acc. prob=0.896]Sample:  26%|██▌       | 561/2200 [00:05, 119.00it/s, step size=1.23e+00, acc. prob=0.899]Sample:  26%|██▌       | 573/2200 [00:05, 112.84it/s, step size=1.23e+00, acc. prob=0.900]Sample:  27%|██▋       | 585/2200 [00:05, 109.64it/s, step size=1.23e+00, acc. prob=0.900]Sample:  27%|██▋       | 597/2200 [00:05, 110.97it/s, step size=1.23e+00, acc. prob=0.902]Sample:  28%|██▊       | 610/2200 [00:05, 113.74it/s, step size=1.23e+00, acc. prob=0.903]Sample:  28%|██▊       | 626/2200 [00:05, 124.29it/s, step size=1.23e+00, acc. prob=0.903]Sample:  29%|██▉       | 639/2200 [00:05, 120.14it/s, step size=1.23e+00, acc. prob=0.902]Sample:  30%|██▉       | 652/2200 [00:06, 116.41it/s, step size=1.23e+00, acc. prob=0.902]Sample:  30%|███       | 664/2200 [00:06, 115.95it/s, step size=1.23e+00, acc. prob=0.902]Sample:  31%|███       | 678/2200 [00:06, 121.63it/s, step size=1.23e+00, acc. prob=0.902]Sample:  31%|███▏      | 692/2200 [00:06, 123.34it/s, step size=1.23e+00, acc. prob=0.903]Sample:  32%|███▏      | 705/2200 [00:06, 113.09it/s, step size=1.23e+00, acc. prob=0.902]Sample:  33%|███▎      | 719/2200 [00:06, 119.32it/s, step size=1.23e+00, acc. prob=0.903]Sample:  33%|███▎      | 732/2200 [00:06, 116.49it/s, step size=1.23e+00, acc. prob=0.904]Sample:  34%|███▍      | 744/2200 [00:06, 116.19it/s, step size=1.23e+00, acc. prob=0.904]Sample:  34%|███▍      | 757/2200 [00:06, 118.99it/s, step size=1.23e+00, acc. prob=0.905]Sample:  35%|███▌      | 770/2200 [00:07, 120.07it/s, step size=1.23e+00, acc. prob=0.907]Sample:  36%|███▌      | 783/2200 [00:07, 114.28it/s, step size=1.23e+00, acc. prob=0.904]Sample:  36%|███▋      | 802/2200 [00:07, 132.12it/s, step size=1.23e+00, acc. prob=0.903]Sample:  37%|███▋      | 816/2200 [00:07, 124.29it/s, step size=1.23e+00, acc. prob=0.904]Sample:  38%|███▊      | 829/2200 [00:07, 124.85it/s, step size=1.23e+00, acc. prob=0.903]Sample:  38%|███▊      | 845/2200 [00:07, 134.52it/s, step size=1.23e+00, acc. prob=0.902]Sample:  39%|███▉      | 859/2200 [00:07, 136.03it/s, step size=1.23e+00, acc. prob=0.901]Sample:  40%|███▉      | 873/2200 [00:07, 131.90it/s, step size=1.23e+00, acc. prob=0.901]Sample:  40%|████      | 887/2200 [00:07, 121.79it/s, step size=1.23e+00, acc. prob=0.902]Sample:  41%|████      | 900/2200 [00:08, 118.56it/s, step size=1.23e+00, acc. prob=0.902]Sample:  42%|████▏     | 915/2200 [00:08, 124.18it/s, step size=1.23e+00, acc. prob=0.902]Sample:  42%|████▏     | 928/2200 [00:08, 124.08it/s, step size=1.23e+00, acc. prob=0.902]Sample:  43%|████▎     | 941/2200 [00:08, 121.34it/s, step size=1.23e+00, acc. prob=0.903]Sample:  43%|████▎     | 955/2200 [00:08, 124.10it/s, step size=1.23e+00, acc. prob=0.904]Sample:  44%|████▍     | 968/2200 [00:08, 123.98it/s, step size=1.23e+00, acc. prob=0.904]Sample:  45%|████▍     | 981/2200 [00:08, 121.59it/s, step size=1.23e+00, acc. prob=0.904]Sample:  45%|████▌     | 994/2200 [00:08, 115.52it/s, step size=1.23e+00, acc. prob=0.905]Sample:  46%|████▌     | 1006/2200 [00:08, 115.79it/s, step size=1.23e+00, acc. prob=0.906]Sample:  46%|████▋     | 1020/2200 [00:09, 121.85it/s, step size=1.23e+00, acc. prob=0.906]Sample:  47%|████▋     | 1033/2200 [00:09, 119.91it/s, step size=1.23e+00, acc. prob=0.907]Sample:  48%|████▊     | 1046/2200 [00:09, 122.06it/s, step size=1.23e+00, acc. prob=0.908]Sample:  48%|████▊     | 1059/2200 [00:09, 124.32it/s, step size=1.23e+00, acc. prob=0.909]Sample:  49%|████▊     | 1072/2200 [00:09, 120.06it/s, step size=1.23e+00, acc. prob=0.908]Sample:  49%|████▉     | 1087/2200 [00:09, 126.73it/s, step size=1.23e+00, acc. prob=0.909]Sample:  50%|█████     | 1100/2200 [00:09, 124.82it/s, step size=1.23e+00, acc. prob=0.909]Sample:  51%|█████     | 1114/2200 [00:09, 128.77it/s, step size=1.23e+00, acc. prob=0.909]Sample:  51%|█████     | 1127/2200 [00:09, 125.51it/s, step size=1.23e+00, acc. prob=0.909]Sample:  52%|█████▏    | 1140/2200 [00:10, 124.30it/s, step size=1.23e+00, acc. prob=0.908]Sample:  52%|█████▏    | 1153/2200 [00:10, 118.56it/s, step size=1.23e+00, acc. prob=0.908]Sample:  53%|█████▎    | 1166/2200 [00:10, 120.42it/s, step size=1.23e+00, acc. prob=0.908]Sample:  54%|█████▎    | 1179/2200 [00:10, 120.74it/s, step size=1.23e+00, acc. prob=0.908]Sample:  54%|█████▍    | 1195/2200 [00:10, 130.74it/s, step size=1.23e+00, acc. prob=0.908]Sample:  55%|█████▍    | 1209/2200 [00:10, 122.52it/s, step size=1.23e+00, acc. prob=0.908]Sample:  56%|█████▌    | 1223/2200 [00:10, 125.92it/s, step size=1.23e+00, acc. prob=0.907]Sample:  56%|█████▌    | 1237/2200 [00:10, 125.98it/s, step size=1.23e+00, acc. prob=0.908]Sample:  57%|█████▋    | 1250/2200 [00:10, 120.08it/s, step size=1.23e+00, acc. prob=0.907]Sample:  57%|█████▋    | 1263/2200 [00:11, 121.79it/s, step size=1.23e+00, acc. prob=0.908]Sample:  58%|█████▊    | 1277/2200 [00:11, 124.44it/s, step size=1.23e+00, acc. prob=0.907]Sample:  59%|█████▊    | 1291/2200 [00:11, 127.20it/s, step size=1.23e+00, acc. prob=0.908]Sample:  59%|█████▉    | 1307/2200 [00:11, 132.38it/s, step size=1.23e+00, acc. prob=0.907]Sample:  60%|██████    | 1321/2200 [00:11, 134.53it/s, step size=1.23e+00, acc. prob=0.907]Sample:  61%|██████    | 1336/2200 [00:11, 138.97it/s, step size=1.23e+00, acc. prob=0.907]Sample:  61%|██████▏   | 1350/2200 [00:11, 129.83it/s, step size=1.23e+00, acc. prob=0.907]Sample:  62%|██████▏   | 1365/2200 [00:11, 133.97it/s, step size=1.23e+00, acc. prob=0.907]Sample:  63%|██████▎   | 1379/2200 [00:11, 130.86it/s, step size=1.23e+00, acc. prob=0.907]Sample:  63%|██████▎   | 1393/2200 [00:12, 128.73it/s, step size=1.23e+00, acc. prob=0.908]Sample:  64%|██████▍   | 1406/2200 [00:12, 124.57it/s, step size=1.23e+00, acc. prob=0.908]Sample:  64%|██████▍   | 1419/2200 [00:12, 120.23it/s, step size=1.23e+00, acc. prob=0.908]Sample:  65%|██████▌   | 1432/2200 [00:12, 115.61it/s, step size=1.23e+00, acc. prob=0.909]Sample:  66%|██████▌   | 1444/2200 [00:12, 114.63it/s, step size=1.23e+00, acc. prob=0.909]Sample:  66%|██████▌   | 1457/2200 [00:12, 115.67it/s, step size=1.23e+00, acc. prob=0.909]Sample:  67%|██████▋   | 1469/2200 [00:12, 115.91it/s, step size=1.23e+00, acc. prob=0.909]Sample:  67%|██████▋   | 1481/2200 [00:12, 111.72it/s, step size=1.23e+00, acc. prob=0.909]Sample:  68%|██████▊   | 1493/2200 [00:12, 110.64it/s, step size=1.23e+00, acc. prob=0.909]Sample:  68%|██████▊   | 1505/2200 [00:13, 112.93it/s, step size=1.23e+00, acc. prob=0.909]Sample:  69%|██████▉   | 1519/2200 [00:13, 119.25it/s, step size=1.23e+00, acc. prob=0.909]Sample:  70%|██████▉   | 1531/2200 [00:13, 116.29it/s, step size=1.23e+00, acc. prob=0.909]Sample:  70%|███████   | 1543/2200 [00:13, 115.70it/s, step size=1.23e+00, acc. prob=0.909]Sample:  71%|███████   | 1555/2200 [00:13, 112.12it/s, step size=1.23e+00, acc. prob=0.909]Sample:  71%|███████   | 1567/2200 [00:13, 111.52it/s, step size=1.23e+00, acc. prob=0.910]Sample:  72%|███████▏  | 1580/2200 [00:13, 114.15it/s, step size=1.23e+00, acc. prob=0.910]Sample:  72%|███████▏  | 1592/2200 [00:13, 114.51it/s, step size=1.23e+00, acc. prob=0.910]Sample:  73%|███████▎  | 1607/2200 [00:13, 123.92it/s, step size=1.23e+00, acc. prob=0.910]Sample:  74%|███████▎  | 1620/2200 [00:13, 119.48it/s, step size=1.23e+00, acc. prob=0.911]Sample:  74%|███████▍  | 1633/2200 [00:14, 119.74it/s, step size=1.23e+00, acc. prob=0.911]Sample:  75%|███████▍  | 1648/2200 [00:14, 124.86it/s, step size=1.23e+00, acc. prob=0.911]Sample:  76%|███████▌  | 1661/2200 [00:14, 125.25it/s, step size=1.23e+00, acc. prob=0.911]Sample:  76%|███████▌  | 1674/2200 [00:14, 126.23it/s, step size=1.23e+00, acc. prob=0.910]Sample:  77%|███████▋  | 1687/2200 [00:14, 126.60it/s, step size=1.23e+00, acc. prob=0.910]Sample:  77%|███████▋  | 1700/2200 [00:14, 124.34it/s, step size=1.23e+00, acc. prob=0.910]Sample:  78%|███████▊  | 1713/2200 [00:14, 123.13it/s, step size=1.23e+00, acc. prob=0.910]Sample:  79%|███████▊  | 1728/2200 [00:14, 130.47it/s, step size=1.23e+00, acc. prob=0.910]Sample:  79%|███████▉  | 1742/2200 [00:14, 126.27it/s, step size=1.23e+00, acc. prob=0.910]Sample:  80%|███████▉  | 1755/2200 [00:15, 126.61it/s, step size=1.23e+00, acc. prob=0.910]Sample:  80%|████████  | 1768/2200 [00:15, 126.64it/s, step size=1.23e+00, acc. prob=0.910]Sample:  81%|████████  | 1781/2200 [00:15, 118.41it/s, step size=1.23e+00, acc. prob=0.910]Sample:  82%|████████▏ | 1793/2200 [00:15, 117.55it/s, step size=1.23e+00, acc. prob=0.910]Sample:  82%|████████▏ | 1805/2200 [00:15, 116.92it/s, step size=1.23e+00, acc. prob=0.910]Sample:  83%|████████▎ | 1820/2200 [00:15, 124.55it/s, step size=1.23e+00, acc. prob=0.910]Sample:  83%|████████▎ | 1834/2200 [00:15, 127.15it/s, step size=1.23e+00, acc. prob=0.910]Sample:  84%|████████▍ | 1847/2200 [00:15, 126.88it/s, step size=1.23e+00, acc. prob=0.910]Sample:  85%|████████▍ | 1860/2200 [00:15, 124.54it/s, step size=1.23e+00, acc. prob=0.909]Sample:  85%|████████▌ | 1873/2200 [00:16, 119.91it/s, step size=1.23e+00, acc. prob=0.910]Sample:  86%|████████▌ | 1886/2200 [00:16, 121.38it/s, step size=1.23e+00, acc. prob=0.910]Sample:  86%|████████▋ | 1899/2200 [00:16, 119.25it/s, step size=1.23e+00, acc. prob=0.910]Sample:  87%|████████▋ | 1912/2200 [00:16, 120.58it/s, step size=1.23e+00, acc. prob=0.910]Sample:  88%|████████▊ | 1925/2200 [00:16, 120.51it/s, step size=1.23e+00, acc. prob=0.910]Sample:  88%|████████▊ | 1938/2200 [00:16, 117.22it/s, step size=1.23e+00, acc. prob=0.910]Sample:  89%|████████▊ | 1950/2200 [00:16, 117.67it/s, step size=1.23e+00, acc. prob=0.910]Sample:  89%|████████▉ | 1962/2200 [00:16, 117.00it/s, step size=1.23e+00, acc. prob=0.910]Sample:  90%|████████▉ | 1974/2200 [00:16, 114.58it/s, step size=1.23e+00, acc. prob=0.911]Sample:  90%|█████████ | 1988/2200 [00:17, 121.81it/s, step size=1.23e+00, acc. prob=0.911]Sample:  91%|█████████ | 2002/2200 [00:17, 126.70it/s, step size=1.23e+00, acc. prob=0.910]Sample:  92%|█████████▏| 2015/2200 [00:17, 127.10it/s, step size=1.23e+00, acc. prob=0.911]Sample:  92%|█████████▏| 2028/2200 [00:17, 126.47it/s, step size=1.23e+00, acc. prob=0.911]Sample:  93%|█████████▎| 2041/2200 [00:17, 119.46it/s, step size=1.23e+00, acc. prob=0.911]Sample:  93%|█████████▎| 2054/2200 [00:17, 114.98it/s, step size=1.23e+00, acc. prob=0.911]Sample:  94%|█████████▍| 2066/2200 [00:17, 109.45it/s, step size=1.23e+00, acc. prob=0.910]Sample:  94%|█████████▍| 2078/2200 [00:17, 105.75it/s, step size=1.23e+00, acc. prob=0.911]Sample:  95%|█████████▍| 2089/2200 [00:17, 105.41it/s, step size=1.23e+00, acc. prob=0.910]Sample:  96%|█████████▌| 2104/2200 [00:18, 114.77it/s, step size=1.23e+00, acc. prob=0.910]Sample:  96%|█████████▋| 2118/2200 [00:18, 118.77it/s, step size=1.23e+00, acc. prob=0.909]Sample:  97%|█████████▋| 2130/2200 [00:18, 116.99it/s, step size=1.23e+00, acc. prob=0.909]Sample:  98%|█████████▊| 2146/2200 [00:18, 125.86it/s, step size=1.23e+00, acc. prob=0.910]Sample:  98%|█████████▊| 2160/2200 [00:18, 127.61it/s, step size=1.23e+00, acc. prob=0.910]Sample:  99%|█████████▉| 2173/2200 [00:18, 125.47it/s, step size=1.23e+00, acc. prob=0.910]Sample:  99%|█████████▉| 2186/2200 [00:18, 126.40it/s, step size=1.23e+00, acc. prob=0.911]Sample: 100%|██████████| 2200/2200 [00:18, 117.36it/s, step size=1.23e+00, acc. prob=0.911]\n\n\n\n# Check model convergence\nintercept_df = pd.DataFrame({'intercept' : mcmc.get_samples()['intercept'].to('cpu')})\nintercept_df.hist()\n\narray([[&lt;Axes: title={'center': 'intercept'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\nThat looks pretty normal now. We’ll need to turn these back into probabilities using the signmoid function.\n\n# Extract samples\nsamples = mcmc.get_samples()['intercept'].to('cpu')\n\n# Plot probabilities\ninferred_probs_df = pd.DataFrame({'probs' : torch.sigmoid(samples)})\ninferred_probs_df.hist()\n\n\ninferred_prob = torch.sigmoid(samples).mean().item()\n\nprint(f\"Inferred probability of a thumb up: {inferred_prob:.4f}\")\n\n# Compute confidence interval\nconfidence_interval_vals = torch.quantile(samples, torch.tensor([0.025, 0.975]))\nconfidence_interval = torch.sigmoid(confidence_interval_vals)\nprint(f\"95% confidence interval: {confidence_interval.tolist()}\")\n\nInferred probability of a thumb up: 0.7327\n95% confidence interval: [0.1406741887331009, 0.9958332180976868]\n\n\n\n\n\n\n\n\n\nOur original estimate using the beta distribution was 0.6649 with a 95% confidence interval: [0.1617867797613144, 0.9869610667228699]. That’s a bit different from this, but the choice of prior influences the outcome. Overall though, that looks like a pretty good estimate of the analytical solution despite only having a single sample.\nWhat happens if we increased the number of samples to 100? How accurate can we get with a moderate amount of data? Let’s say we want to model something with a 90% upvote rate, so 90 thumbs up and 10 thumbs down.\n\n# Data: 90 thumbs up, 10 thumbs down\ndata = torch.cat((torch.ones(90), torch.zeros(10)))\n\n# Rerun model with reduced steps\nnuts_kernel = NUTS(beta_model)\nmcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=200)\nmcmc.run(data)\n\n# Extract samples\nsamples = mcmc.get_samples()\nprob_thumb_up_samples = samples['prob_thumb_up']\n\n# Make histogram of samples\nsamples_df = pd.DataFrame(samples)\nsamples_df.hist()\n\n# Compute confidence interval\nconfidence_interval = torch.quantile(prob_thumb_up_samples, torch.tensor([0.025, 0.975]))\n\nprint(f\"Estimated probability of thumb up: {prob_thumb_up_samples.mean().item():.4f}\")\nprint(f\"95% confidence interval: {confidence_interval.tolist()}\")\n\nWarmup:   0%|          | 0/2200 [00:00, ?it/s]Warmup:   1%|▏         | 28/2200 [00:00, 267.89it/s, step size=1.64e-01, acc. prob=0.765]Warmup:   3%|▎         | 65/2200 [00:00, 323.13it/s, step size=3.72e-01, acc. prob=0.786]Warmup:   5%|▍         | 103/2200 [00:00, 333.68it/s, step size=2.77e-01, acc. prob=0.779]Warmup:   6%|▌         | 137/2200 [00:00, 326.09it/s, step size=1.09e+00, acc. prob=0.787]Warmup:   8%|▊         | 170/2200 [00:00, 302.44it/s, step size=1.28e+00, acc. prob=0.782]Warmup:   9%|▉         | 201/2200 [00:00, 294.67it/s, step size=1.24e+00, acc. prob=0.699]Sample:  11%|█         | 241/2200 [00:00, 325.48it/s, step size=1.24e+00, acc. prob=0.917]Sample:  13%|█▎        | 277/2200 [00:00, 334.84it/s, step size=1.24e+00, acc. prob=0.911]Sample:  15%|█▍        | 320/2200 [00:00, 363.37it/s, step size=1.24e+00, acc. prob=0.911]Sample:  16%|█▌        | 357/2200 [00:01, 361.53it/s, step size=1.24e+00, acc. prob=0.914]Sample:  18%|█▊        | 396/2200 [00:01, 368.89it/s, step size=1.24e+00, acc. prob=0.914]Sample:  20%|█▉        | 434/2200 [00:01, 363.52it/s, step size=1.24e+00, acc. prob=0.916]Sample:  22%|██▏       | 475/2200 [00:01, 374.98it/s, step size=1.24e+00, acc. prob=0.916]Sample:  23%|██▎       | 515/2200 [00:01, 380.10it/s, step size=1.24e+00, acc. prob=0.917]Sample:  25%|██▌       | 555/2200 [00:01, 383.61it/s, step size=1.24e+00, acc. prob=0.913]Sample:  27%|██▋       | 597/2200 [00:01, 393.29it/s, step size=1.24e+00, acc. prob=0.912]Sample:  29%|██▉       | 637/2200 [00:01, 387.24it/s, step size=1.24e+00, acc. prob=0.916]Sample:  31%|███       | 678/2200 [00:01, 392.68it/s, step size=1.24e+00, acc. prob=0.915]Sample:  33%|███▎      | 718/2200 [00:02, 379.22it/s, step size=1.24e+00, acc. prob=0.918]Sample:  34%|███▍      | 757/2200 [00:02, 380.69it/s, step size=1.24e+00, acc. prob=0.919]Sample:  36%|███▌      | 797/2200 [00:02, 385.18it/s, step size=1.24e+00, acc. prob=0.921]Sample:  38%|███▊      | 836/2200 [00:02, 377.67it/s, step size=1.24e+00, acc. prob=0.921]Sample:  40%|███▉      | 874/2200 [00:02, 358.66it/s, step size=1.24e+00, acc. prob=0.922]Sample:  41%|████▏     | 911/2200 [00:02, 350.98it/s, step size=1.24e+00, acc. prob=0.921]Sample:  43%|████▎     | 953/2200 [00:02, 367.28it/s, step size=1.24e+00, acc. prob=0.921]Sample:  45%|████▌     | 994/2200 [00:02, 376.22it/s, step size=1.24e+00, acc. prob=0.920]Sample:  47%|████▋     | 1032/2200 [00:02, 367.79it/s, step size=1.24e+00, acc. prob=0.919]Sample:  49%|████▊     | 1071/2200 [00:02, 370.97it/s, step size=1.24e+00, acc. prob=0.921]Sample:  50%|█████     | 1109/2200 [00:03, 366.65it/s, step size=1.24e+00, acc. prob=0.921]Sample:  52%|█████▏    | 1146/2200 [00:03, 356.33it/s, step size=1.24e+00, acc. prob=0.922]Sample:  54%|█████▍    | 1184/2200 [00:03, 362.05it/s, step size=1.24e+00, acc. prob=0.922]Sample:  56%|█████▌    | 1221/2200 [00:03, 362.26it/s, step size=1.24e+00, acc. prob=0.923]Sample:  57%|█████▋    | 1258/2200 [00:03, 357.17it/s, step size=1.24e+00, acc. prob=0.923]Sample:  59%|█████▉    | 1298/2200 [00:03, 367.41it/s, step size=1.24e+00, acc. prob=0.923]Sample:  61%|██████    | 1338/2200 [00:03, 375.89it/s, step size=1.24e+00, acc. prob=0.922]Sample:  63%|██████▎   | 1377/2200 [00:03, 380.02it/s, step size=1.24e+00, acc. prob=0.922]Sample:  64%|██████▍   | 1416/2200 [00:03, 378.51it/s, step size=1.24e+00, acc. prob=0.921]Sample:  66%|██████▌   | 1454/2200 [00:04, 361.91it/s, step size=1.24e+00, acc. prob=0.921]Sample:  68%|██████▊   | 1492/2200 [00:04, 366.55it/s, step size=1.24e+00, acc. prob=0.921]Sample:  70%|██████▉   | 1529/2200 [00:04, 357.32it/s, step size=1.24e+00, acc. prob=0.921]Sample:  71%|███████   | 1567/2200 [00:04, 360.72it/s, step size=1.24e+00, acc. prob=0.922]Sample:  73%|███████▎  | 1608/2200 [00:04, 372.81it/s, step size=1.24e+00, acc. prob=0.921]Sample:  75%|███████▍  | 1648/2200 [00:04, 379.63it/s, step size=1.24e+00, acc. prob=0.922]Sample:  77%|███████▋  | 1695/2200 [00:04, 403.74it/s, step size=1.24e+00, acc. prob=0.922]Sample:  79%|███████▉  | 1736/2200 [00:04, 374.74it/s, step size=1.24e+00, acc. prob=0.922]Sample:  81%|████████  | 1778/2200 [00:04, 385.25it/s, step size=1.24e+00, acc. prob=0.922]Sample:  83%|████████▎ | 1817/2200 [00:04, 381.17it/s, step size=1.24e+00, acc. prob=0.922]Sample:  84%|████████▍ | 1856/2200 [00:05, 380.97it/s, step size=1.24e+00, acc. prob=0.922]Sample:  86%|████████▋ | 1898/2200 [00:05, 391.10it/s, step size=1.24e+00, acc. prob=0.922]Sample:  88%|████████▊ | 1938/2200 [00:05, 376.16it/s, step size=1.24e+00, acc. prob=0.921]Sample:  90%|████████▉ | 1979/2200 [00:05, 385.78it/s, step size=1.24e+00, acc. prob=0.920]Sample:  92%|█████████▏| 2018/2200 [00:05, 375.08it/s, step size=1.24e+00, acc. prob=0.920]Sample:  93%|█████████▎| 2056/2200 [00:05, 368.07it/s, step size=1.24e+00, acc. prob=0.920]Sample:  95%|█████████▌| 2094/2200 [00:05, 369.37it/s, step size=1.24e+00, acc. prob=0.921]Sample:  97%|█████████▋| 2136/2200 [00:05, 382.80it/s, step size=1.24e+00, acc. prob=0.920]Sample:  99%|█████████▉| 2175/2200 [00:05, 376.20it/s, step size=1.24e+00, acc. prob=0.921]Sample: 100%|██████████| 2200/2200 [00:05, 368.32it/s, step size=1.24e+00, acc. prob=0.921]\n\n\nEstimated probability of thumb up: 0.8923\n95% confidence interval: [0.827656626701355, 0.9420859217643738]\n\n\n\n\n\n\n\n\n\nAn estimate of 0.89 for a 90% upvoted piece of content is pretty good, and the spread on the estimate is much tighter than before.\nThis is still a really simple model, though. For more complicated models, MCMC might be prohibitively slow. For real life scenarios, it’s inlikely to be doing something with this few samples and this simple of a model. In these cases, you might want to try variational inference (VI) instead of MCMC. VI allows you to turn the sampling problem into an optimization problem, where you optimize the parameters of a distirbution directly. Here I’m going to use the Adam optomizer, which is short for adaptive gradient descent. It’s popular in lots of mcahine learning applications due to its speed and ability to handle sparse gradients. We can check to see how well Adam is optimizing by checking to see if the evidence lower bound (ELBO) converges. We can pump up our data a bit, too.\n\n# Define the guide (variational posterior)\ndef guide(data):\n    # Variational parameters for the intercept\n    mean_q = pyro.param(\"mean_q\", torch.tensor(0.0, device=device))\n    scale_q = pyro.param(\"scale_q\", torch.tensor(1.0, device=device), constraint=dist.constraints.positive)\n    \n    pyro.sample(\"intercept\", dist.Normal(mean_q, scale_q))\n\n# Data: 900 thumbs up, 100 thumbs down, and make sure its in the right place\ndata = torch.cat((torch.ones(900), torch.zeros(100))).to(device)\n\n# Set up the optimizer and inference algorithm\noptimizer = Adam({\"lr\": torch.tensor(0.001, device=device)})  # Learning rate\nsvi = SVI(logistic_model, guide, optimizer, loss=Trace_ELBO())\n\n# Perform optimization\nnum_steps = 10000\nlosses = []\nfor step in range(num_steps):\n    loss = svi.step(data)  # Perform one step of optimization\n    losses.append(loss)\n    if step % 1000 == 0:\n        print(f\"Step {step} - Loss: {loss}\")\n\n# Inspect learned parameters\nmean_q = pyro.param(\"mean_q\").item()\nscale_q = pyro.param(\"scale_q\").item()\nprint(f\"Posterior Mean: {mean_q}, Posterior Std: {scale_q}\")\n\n# Plot ELBO convergence\nimport matplotlib.pyplot as plt\nplt.plot(losses)\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"ELBO Loss\")\nplt.title(\"ELBO Convergence\")\nplt.show()\n\nStep 0 - Loss: 530.4799635410309\nStep 1000 - Loss: 450.63120698928833\nStep 2000 - Loss: 603.2254050970078\nStep 3000 - Loss: 363.6408305466175\nStep 4000 - Loss: 337.36681163311005\nStep 5000 - Loss: 328.7159623503685\nStep 6000 - Loss: 327.6683760881424\nStep 7000 - Loss: 328.99758183956146\nStep 8000 - Loss: 328.5293536186218\nStep 9000 - Loss: 328.31051325798035\nPosterior Mean: 2.205451250076294, Posterior Std: 0.15027137100696564\n\n\n\n\n\n\n\n\n\nThat elbow plot clearly converges, so it looks like the optimizer worked well. All that’s left is seeing if the estimate we got for the posterior probability of the intercept is accurate. To do that, we’ll need to transform our\n\nimport math\n\n# Convert posterior mean (log-odds) to probability\nposterior_mean = pyro.param(\"mean_q\").item()\n\n# Probability from logistic function\nposterior_probability = 1 / (1 + math.exp(-posterior_mean))\n\nprint(posterior_probability)\n\n0.900737967976173\n\n\nA perfect estimate!"
  },
  {
    "objectID": "posts/20240105/index.html",
    "href": "posts/20240105/index.html",
    "title": "Getting Around Istanbul",
    "section": "",
    "text": "Summary:\n\nThe metro and ferries are the best public transit options\nGoogle Maps works, but Moovit has much better coverage for ferry routes\nAvoid relying on taxis unless absolutely necessary\nUber calls taxis and you will likely have an excessive wait\nAvoid minibuses (light blue buses on Google Maps)\n\nIf you don’t like my guide, you can read more about getting to and from the airport here\nIf you don’t like my guide, you can read more about public transit here\n\n\nGeneral Information\nIstanbul has a very well-developed public transit system. It spans the Bosphorous Strait to connect both sides of city and connects both passenger airports (IST and SAW) to the city center. Public transit, especially the ferries and metro, are the best way to get around the city due to rush hour traffic. The metro system covers all of the main touristic areas of the city and is easy to use. On weeknights most public transit shuts down around midnight, so plan on staying near your hotel if you want to go out late. Google Maps does a good job of providing routes and even has several privately owned airport bus companies listed. Almost all of the public transit can be accessed using an IstanbulKart that can be purchased from and reloaded at yellow kiosks in metro stations. In tourist areas, you’re more likely to find kiosks that have an English option. Each connection you use will incur a new charge, so make sure your IstanbulKart is loaded up. And importantly, most IstanbulKart machines cannot take bills larger than 100 TL! Each leg of a journey will probably cost ~10TL\n\n\nModes of Transit\n\nMetro\n\n\n\nIstanbul metro map\n\n\nThe metro system in Istanbul is clean and easy to use. It functions just like the metro lines in most major cities. Expect trains every 5-10 min in most cases. Trains run from 6:00 AM to midnight, but there is uninterrupted 24-hour service with trains every 30 min Friday and Saturday night. This should be one of your primary ways of getting around the city. There is only one metro line that crosses the Bosphorous Strait, the Marmaray (gray line). This line is more expensive.\n\n\nFerries\nFerries in Istanbul are fully integrated into the public transit network, so you can use your IstanbulKart to board them. They are very convenient, and should also be one of your primary modes of transportation. They are automatically included in Google Maps routes and marked with a blue boat sign. At many of the ferry stations, there will be several wharfs with different ferries. For the busiest ferries, there can even be two docks running the same route at staggered intervals. Make sure you are getting on the right one by checking the signs! Public ferry schedules can be found here: https://sehirhatlari.istanbul/en/timetables . There are also private ferries (which can still be accessed using your IstanbulKart), but these are not included in Google Maps. Roughly half of the ferries moving on major routes are operated by private companies. If you see a ferry on Google Maps that’s running on the :00 and :30 marks, there is probably another dock nearby with a private ferry that leaves on the :15 and :45 marks. Private ferries are included in the Moovit app.\n\n\nBuses\nThere are three types of buses in Istanbul that might be included in your route.\n\nStandard city buses: These are big yellow and black buses, and they have a yellow bus symbol on Google Maps. You pay when you get on. Most buses will stop running before midnight.\nMetrobuses: These have a beige bus symbol on Google Maps. These buses have their own lanes and move pretty quickly. You pay when you enter the station as if it were a metro.\nMinibuses: These are tiny death traps with no ventilation. They are marked with a light blue bus symbol on Google Maps. I recommend not using them because they only take cash and you have to tell them your destination.\n\n\n\nTaxis\nAvoid taxis unless absolutely necessary. They are notorious for scamming people, often do not speak English, and will not know how to get to your destination. Many taxis are cash only. If you have to take a taxi, make sure the meter is running as soon as you get in the cab, and pull up the route on your phone so that you see if they make any detours. There may be additional fees associated with crossing the bridges, but these should be small (~20 TL).\n\n\nGetting to/from the Airport\nBoth Istanbul airports (IST and SAW) are a ways outside the city, so it can take some time to get to the city center where your hotels probably are.\nThere are several ways you can get to/from the airport. The easiest way is going to be getting your hotel to call you an airport shuttle. Note that the wedding venue (A11 Hotel Bosphorus) provides an airport shuttle. You also might be able to save yourself a few dollars by booking a shuttle yourself with a private shuttle service such as https://airporttransfer.vip/ . This should cost ~€40. I’ve seen good reviews for this service, but I haven’t used it personally. Driving directly to your hotel should take ~45 min, but traffic can add up to an hour if you’re landing during rush hour.\nAnother way is to take an airport bus. There are private companies that offer reliable service between the airport and popular destinations in Istanbul. These run 24/7, but at 30-60 min intervals. The most popular is Havaist, which leaves from the -2 floor of the IST airport https://istanbul-international-airport.com/transportation/bus/ . If you are staying in Uskudar, you can take the Havaist bus to Kadikoy, followed by the metro from Kadikoy to Uskudar. This is two stops, but requires changing lines at the first stop. The total cost of this trip will be ~$7, not including buying an IstanbulKart to use the public transit. You can also take the Havaist bus to Besiktas and take a ferry from Besiktas to Uskudar.\nThe airports also connects directly to the metro system. You can connect to either the historic areas of Istanbul or Uskudar, but it will require several transfers, and take slightly longer than the Havaist bus. You can get to Uskudar by taking the M11-M7-M2-Marmaray route. Most other areas of the city—such as Galata and Eminonu—are accessible via the M2 line without crossing the Bosphorous using the Marmaray. Some of the stations are quite large, and it may not be desirable to lug around a ton of bags."
  }
]